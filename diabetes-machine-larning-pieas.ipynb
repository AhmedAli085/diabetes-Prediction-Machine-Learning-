{"metadata":{"colab":{"provenance":[]},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":482,"sourceType":"datasetVersion","datasetId":228}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":149.061324,"end_time":"2024-05-15T03:42:22.561340","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-05-15T03:39:53.500016","version":"2.5.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Diabetes Prediction","metadata":{"id":"sKCvjsCcut43","papermill":{"duration":0.015824,"end_time":"2024-05-15T03:39:56.712378","exception":false,"start_time":"2024-05-15T03:39:56.696554","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"Link to the Dataset:\n[Pima Indians Diabetes Database](https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database)","metadata":{"id":"OlnLNi1_MBSL","papermill":{"duration":0.014399,"end_time":"2024-05-15T03:39:56.741828","exception":false,"start_time":"2024-05-15T03:39:56.727429","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"#About Dataset:\n##`Context`\nThis dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\n\n##`Content`\nThe datasets consists of several medical predictor variables and one target variable, Outcome. Predictor variables includes the number of pregnancies the patient has had, their BMI, insulin level, age, and so on.","metadata":{"papermill":{"duration":0.014431,"end_time":"2024-05-15T03:39:56.770828","exception":false,"start_time":"2024-05-15T03:39:56.756397","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np","metadata":{"id":"15WXrqvfusaI","papermill":{"duration":1.044976,"end_time":"2024-05-15T03:39:57.831889","exception":false,"start_time":"2024-05-15T03:39:56.786913","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-28T20:31:59.257981Z","iopub.execute_input":"2024-05-28T20:31:59.258701Z","iopub.status.idle":"2024-05-28T20:32:00.385121Z","shell.execute_reply.started":"2024-05-28T20:31:59.258656Z","shell.execute_reply":"2024-05-28T20:32:00.383962Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# set seed for reproducibility\nSEED = 20\nnp.random.seed(SEED)","metadata":{"id":"U_W-eavPyLD9","papermill":{"duration":0.024424,"end_time":"2024-05-15T03:39:57.871667","exception":false,"start_time":"2024-05-15T03:39:57.847243","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-28T20:32:00.389099Z","iopub.execute_input":"2024-05-28T20:32:00.390262Z","iopub.status.idle":"2024-05-28T20:32:00.396691Z","shell.execute_reply.started":"2024-05-28T20:32:00.390219Z","shell.execute_reply":"2024-05-28T20:32:00.395195Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Loading Data\ndf = pd.read_csv('../input/pima-indians-diabetes-database/diabetes.csv')\ndf.head()","metadata":{"id":"IMwQp-r8ylN9","outputId":"0536acde-c648-465f-bbb2-543d927c0b79","papermill":{"duration":0.065015,"end_time":"2024-05-15T03:39:57.952507","exception":false,"start_time":"2024-05-15T03:39:57.887492","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-28T20:32:00.398462Z","iopub.execute_input":"2024-05-28T20:32:00.399069Z","iopub.status.idle":"2024-05-28T20:32:00.451111Z","shell.execute_reply.started":"2024-05-28T20:32:00.399037Z","shell.execute_reply":"2024-05-28T20:32:00.449678Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n0            6      148             72             35        0  33.6   \n1            1       85             66             29        0  26.6   \n2            8      183             64              0        0  23.3   \n3            1       89             66             23       94  28.1   \n4            0      137             40             35      168  43.1   \n\n   DiabetesPedigreeFunction  Age  Outcome  \n0                     0.627   50        1  \n1                     0.351   31        0  \n2                     0.672   32        1  \n3                     0.167   21        0  \n4                     2.288   33        1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pregnancies</th>\n      <th>Glucose</th>\n      <th>BloodPressure</th>\n      <th>SkinThickness</th>\n      <th>Insulin</th>\n      <th>BMI</th>\n      <th>DiabetesPedigreeFunction</th>\n      <th>Age</th>\n      <th>Outcome</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6</td>\n      <td>148</td>\n      <td>72</td>\n      <td>35</td>\n      <td>0</td>\n      <td>33.6</td>\n      <td>0.627</td>\n      <td>50</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>85</td>\n      <td>66</td>\n      <td>29</td>\n      <td>0</td>\n      <td>26.6</td>\n      <td>0.351</td>\n      <td>31</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8</td>\n      <td>183</td>\n      <td>64</td>\n      <td>0</td>\n      <td>0</td>\n      <td>23.3</td>\n      <td>0.672</td>\n      <td>32</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>89</td>\n      <td>66</td>\n      <td>23</td>\n      <td>94</td>\n      <td>28.1</td>\n      <td>0.167</td>\n      <td>21</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>137</td>\n      <td>40</td>\n      <td>35</td>\n      <td>168</td>\n      <td>43.1</td>\n      <td>2.288</td>\n      <td>33</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Exploratory Data Analysis","metadata":{"id":"UDHUDMCszuNC","papermill":{"duration":0.014584,"end_time":"2024-05-15T03:39:57.981983","exception":false,"start_time":"2024-05-15T03:39:57.967399","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# checking null values\ndf.isnull().sum()","metadata":{"id":"Op-XGDHwz03Q","outputId":"c8077d6a-5b62-4096-b952-afa09a7b721e","papermill":{"duration":0.029323,"end_time":"2024-05-15T03:39:58.026934","exception":false,"start_time":"2024-05-15T03:39:57.997611","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-28T20:32:00.454421Z","iopub.execute_input":"2024-05-28T20:32:00.455682Z","iopub.status.idle":"2024-05-28T20:32:00.466903Z","shell.execute_reply.started":"2024-05-28T20:32:00.455631Z","shell.execute_reply":"2024-05-28T20:32:00.465662Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"Pregnancies                 0\nGlucose                     0\nBloodPressure               0\nSkinThickness               0\nInsulin                     0\nBMI                         0\nDiabetesPedigreeFunction    0\nAge                         0\nOutcome                     0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"df.info()","metadata":{"id":"v2KDfXpnz9uM","outputId":"dbd3ca88-ef2f-4787-ac8a-890e5fef5e59","papermill":{"duration":0.044579,"end_time":"2024-05-15T03:39:58.086509","exception":false,"start_time":"2024-05-15T03:39:58.041930","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-28T20:32:00.468856Z","iopub.execute_input":"2024-05-28T20:32:00.469472Z","iopub.status.idle":"2024-05-28T20:32:00.496258Z","shell.execute_reply.started":"2024-05-28T20:32:00.469428Z","shell.execute_reply":"2024-05-28T20:32:00.494991Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 768 entries, 0 to 767\nData columns (total 9 columns):\n #   Column                    Non-Null Count  Dtype  \n---  ------                    --------------  -----  \n 0   Pregnancies               768 non-null    int64  \n 1   Glucose                   768 non-null    int64  \n 2   BloodPressure             768 non-null    int64  \n 3   SkinThickness             768 non-null    int64  \n 4   Insulin                   768 non-null    int64  \n 5   BMI                       768 non-null    float64\n 6   DiabetesPedigreeFunction  768 non-null    float64\n 7   Age                       768 non-null    int64  \n 8   Outcome                   768 non-null    int64  \ndtypes: float64(2), int64(7)\nmemory usage: 54.1 KB\n","output_type":"stream"}]},{"cell_type":"code","source":"# Check for zero values in all columns\nzero_values = (df == 0).sum()\n\n# Display the columns with zero values\nprint(\"Columns with zero values:\")\nprint(zero_values[zero_values > 0])\n","metadata":{"id":"TLK7G2bZ0Da1","outputId":"008eb5ee-2855-490b-9fe5-7b5de7633913","papermill":{"duration":0.029951,"end_time":"2024-05-15T03:39:58.132828","exception":false,"start_time":"2024-05-15T03:39:58.102877","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-28T20:32:00.497876Z","iopub.execute_input":"2024-05-28T20:32:00.498566Z","iopub.status.idle":"2024-05-28T20:32:00.515692Z","shell.execute_reply.started":"2024-05-28T20:32:00.498529Z","shell.execute_reply":"2024-05-28T20:32:00.514641Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Columns with zero values:\nPregnancies      111\nGlucose            5\nBloodPressure     35\nSkinThickness    227\nInsulin          374\nBMI               11\nOutcome          500\ndtype: int64\n","output_type":"stream"}]},{"cell_type":"markdown","source":"We have many zero values will definetely effect the model accuracy. We need to convert them with `nan` values.","metadata":{"id":"jEeynUVD2xLj","papermill":{"duration":0.015142,"end_time":"2024-05-15T03:39:58.163111","exception":false,"start_time":"2024-05-15T03:39:58.147969","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"Function to replace zero values with `nan`","metadata":{"id":"iaA2ntx93pID","papermill":{"duration":0.01469,"end_time":"2024-05-15T03:39:58.192966","exception":false,"start_time":"2024-05-15T03:39:58.178276","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def replace_zero(df):\n    df_nan=df.copy(deep=True)\n    cols = [\"Glucose\",\"BloodPressure\",\"SkinThickness\",\"Insulin\",\"BMI\"]\n    df_nan[cols] = df_nan[cols].replace({0:np.nan})\n    return df_nan\ndf_nan=replace_zero(df)","metadata":{"id":"GnLelDTD3SHW","papermill":{"duration":0.03175,"end_time":"2024-05-15T03:39:58.239786","exception":false,"start_time":"2024-05-15T03:39:58.208036","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-28T20:32:00.517346Z","iopub.execute_input":"2024-05-28T20:32:00.517768Z","iopub.status.idle":"2024-05-28T20:32:00.537455Z","shell.execute_reply.started":"2024-05-28T20:32:00.517725Z","shell.execute_reply":"2024-05-28T20:32:00.536279Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def find_median(frame,var):\n    temp = frame[frame[var].notnull()]\n    temp = frame[[var,'Outcome']].groupby('Outcome')[[var]].median().reset_index()\n    return temp","metadata":{"id":"3-Bcd4Av6vN7","papermill":{"duration":0.0245,"end_time":"2024-05-15T03:39:58.279212","exception":false,"start_time":"2024-05-15T03:39:58.254712","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-28T20:32:00.539227Z","iopub.execute_input":"2024-05-28T20:32:00.540516Z","iopub.status.idle":"2024-05-28T20:32:00.548254Z","shell.execute_reply.started":"2024-05-28T20:32:00.540464Z","shell.execute_reply":"2024-05-28T20:32:00.546862Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# function to replace null values\ndef replace_null(frame,var):\n    median_df=find_median(frame,var)\n    var_0=median_df[var].iloc[0]\n    var_1=median_df[var].iloc[1]\n    frame.loc[(frame['Outcome'] == 0) & (frame[var].isnull()), var] = var_0\n    frame.loc[(frame['Outcome'] == 1) & (frame[var].isnull()), var] = var_1\n    return frame[var].isnull().sum()","metadata":{"id":"ssojfaBmEEdU","papermill":{"duration":0.02667,"end_time":"2024-05-15T03:39:58.320986","exception":false,"start_time":"2024-05-15T03:39:58.294316","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-28T20:32:00.549905Z","iopub.execute_input":"2024-05-28T20:32:00.550676Z","iopub.status.idle":"2024-05-28T20:32:00.565942Z","shell.execute_reply.started":"2024-05-28T20:32:00.550639Z","shell.execute_reply":"2024-05-28T20:32:00.564614Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"print(str(replace_null(df_nan,'Glucose'))+ ' Nulls for Glucose')\nprint(str(replace_null(df_nan,'SkinThickness'))+ ' Nulls for SkinThickness')\nprint(str(replace_null(df_nan,'Insulin'))+ ' Nulls for Insulin')\nprint(str(replace_null(df_nan,'BMI'))+ ' Nulls for BMI')\nprint(str(replace_null(df_nan,'BloodPressure'))+ ' Nulls for BloodPressure')\n# We have successfully handled Nulls","metadata":{"id":"6cskyYbwJ7x2","outputId":"2ae22726-a2b7-42b0-ee52-a1b3b212ed31","papermill":{"duration":0.063899,"end_time":"2024-05-15T03:39:58.400527","exception":false,"start_time":"2024-05-15T03:39:58.336628","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-28T20:32:00.570600Z","iopub.execute_input":"2024-05-28T20:32:00.571019Z","iopub.status.idle":"2024-05-28T20:32:00.620335Z","shell.execute_reply.started":"2024-05-28T20:32:00.570986Z","shell.execute_reply":"2024-05-28T20:32:00.619386Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"0 Nulls for Glucose\n0 Nulls for SkinThickness\n0 Nulls for Insulin\n0 Nulls for BMI\n0 Nulls for BloodPressure\n","output_type":"stream"}]},{"cell_type":"markdown","source":"All null values has been successfully imputed with their median.\n","metadata":{"id":"kdfwbmMPNtPk","papermill":{"duration":0.014882,"end_time":"2024-05-15T03:39:58.430878","exception":false,"start_time":"2024-05-15T03:39:58.415996","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"### Data Scaling","metadata":{"id":"ZVaqZn1gRUka","papermill":{"duration":0.015789,"end_time":"2024-05-15T03:39:58.462527","exception":false,"start_time":"2024-05-15T03:39:58.446738","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# We need to scale our data for uniformity.\nfrom sklearn.preprocessing import StandardScaler\ndef std_scalar(df):\n    std_X = StandardScaler()\n    x =  pd.DataFrame(std_X.fit_transform(df.drop([\"Outcome\"],axis = 1),),\n            columns=['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n           'BMI', 'DiabetesPedigreeFunction', 'Age'])\n    y=df[\"Outcome\"]\n    return x,y","metadata":{"id":"9Qs7jc7tP4hm","papermill":{"duration":1.395629,"end_time":"2024-05-15T03:39:59.873785","exception":false,"start_time":"2024-05-15T03:39:58.478156","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-28T20:32:00.622022Z","iopub.execute_input":"2024-05-28T20:32:00.622664Z","iopub.status.idle":"2024-05-28T20:32:01.972619Z","shell.execute_reply.started":"2024-05-28T20:32:00.622630Z","shell.execute_reply":"2024-05-28T20:32:01.971466Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"### Data After Scaling","metadata":{"id":"ZxP07JgErNe0","papermill":{"duration":0.0164,"end_time":"2024-05-15T03:39:59.905580","exception":false,"start_time":"2024-05-15T03:39:59.889180","status":"completed"},"tags":[]}},{"cell_type":"code","source":"X,Y=std_scalar(df_nan)\nX.describe()","metadata":{"id":"l6X0376grUV_","outputId":"b8dbf124-ad02-4008-846f-cf9cd603b449","papermill":{"duration":0.067448,"end_time":"2024-05-15T03:39:59.988200","exception":false,"start_time":"2024-05-15T03:39:59.920752","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-28T20:32:01.974408Z","iopub.execute_input":"2024-05-28T20:32:01.975683Z","iopub.status.idle":"2024-05-28T20:32:02.032743Z","shell.execute_reply.started":"2024-05-28T20:32:01.975642Z","shell.execute_reply":"2024-05-28T20:32:02.031159Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"        Pregnancies       Glucose  BloodPressure  SkinThickness       Insulin  \\\ncount  7.680000e+02  7.680000e+02   7.680000e+02   7.680000e+02  7.680000e+02   \nmean  -6.476301e-17  1.480297e-16  -3.978299e-16   8.095376e-18 -3.469447e-18   \nstd    1.000652e+00  1.000652e+00   1.000652e+00   1.000652e+00  1.000652e+00   \nmin   -1.141852e+00 -2.551447e+00  -3.999727e+00  -2.486187e+00 -1.434747e+00   \n25%   -8.448851e-01 -7.202356e-01  -6.934382e-01  -4.603073e-01 -4.408430e-01   \n50%   -2.509521e-01 -1.536274e-01  -3.218035e-02  -1.226607e-01 -4.408430e-01   \n75%    6.399473e-01  6.100618e-01   6.290775e-01   3.275348e-01  3.116039e-01   \nmax    3.906578e+00  2.539814e+00   4.100681e+00   7.868309e+00  7.909072e+00   \n\n                BMI  DiabetesPedigreeFunction           Age  \ncount  7.680000e+02              7.680000e+02  7.680000e+02  \nmean   1.318390e-16              2.451743e-16  1.931325e-16  \nstd    1.000652e+00              1.000652e+00  1.000652e+00  \nmin   -2.070186e+00             -1.189553e+00 -1.041549e+00  \n25%   -7.176590e-01             -6.889685e-01 -7.862862e-01  \n50%   -5.593870e-02             -3.001282e-01 -3.608474e-01  \n75%    6.057816e-01              4.662269e-01  6.602056e-01  \nmax    5.041489e+00              5.883565e+00  4.063716e+00  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pregnancies</th>\n      <th>Glucose</th>\n      <th>BloodPressure</th>\n      <th>SkinThickness</th>\n      <th>Insulin</th>\n      <th>BMI</th>\n      <th>DiabetesPedigreeFunction</th>\n      <th>Age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>7.680000e+02</td>\n      <td>7.680000e+02</td>\n      <td>7.680000e+02</td>\n      <td>7.680000e+02</td>\n      <td>7.680000e+02</td>\n      <td>7.680000e+02</td>\n      <td>7.680000e+02</td>\n      <td>7.680000e+02</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>-6.476301e-17</td>\n      <td>1.480297e-16</td>\n      <td>-3.978299e-16</td>\n      <td>8.095376e-18</td>\n      <td>-3.469447e-18</td>\n      <td>1.318390e-16</td>\n      <td>2.451743e-16</td>\n      <td>1.931325e-16</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.000652e+00</td>\n      <td>1.000652e+00</td>\n      <td>1.000652e+00</td>\n      <td>1.000652e+00</td>\n      <td>1.000652e+00</td>\n      <td>1.000652e+00</td>\n      <td>1.000652e+00</td>\n      <td>1.000652e+00</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-1.141852e+00</td>\n      <td>-2.551447e+00</td>\n      <td>-3.999727e+00</td>\n      <td>-2.486187e+00</td>\n      <td>-1.434747e+00</td>\n      <td>-2.070186e+00</td>\n      <td>-1.189553e+00</td>\n      <td>-1.041549e+00</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>-8.448851e-01</td>\n      <td>-7.202356e-01</td>\n      <td>-6.934382e-01</td>\n      <td>-4.603073e-01</td>\n      <td>-4.408430e-01</td>\n      <td>-7.176590e-01</td>\n      <td>-6.889685e-01</td>\n      <td>-7.862862e-01</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>-2.509521e-01</td>\n      <td>-1.536274e-01</td>\n      <td>-3.218035e-02</td>\n      <td>-1.226607e-01</td>\n      <td>-4.408430e-01</td>\n      <td>-5.593870e-02</td>\n      <td>-3.001282e-01</td>\n      <td>-3.608474e-01</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>6.399473e-01</td>\n      <td>6.100618e-01</td>\n      <td>6.290775e-01</td>\n      <td>3.275348e-01</td>\n      <td>3.116039e-01</td>\n      <td>6.057816e-01</td>\n      <td>4.662269e-01</td>\n      <td>6.602056e-01</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>3.906578e+00</td>\n      <td>2.539814e+00</td>\n      <td>4.100681e+00</td>\n      <td>7.868309e+00</td>\n      <td>7.909072e+00</td>\n      <td>5.041489e+00</td>\n      <td>5.883565e+00</td>\n      <td>4.063716e+00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"std_x = StandardScaler()","metadata":{"id":"aMWHNx_LrVdJ","papermill":{"duration":0.103284,"end_time":"2024-05-15T03:40:00.107440","exception":false,"start_time":"2024-05-15T03:40:00.004156","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-28T20:32:02.034545Z","iopub.execute_input":"2024-05-28T20:32:02.035569Z","iopub.status.idle":"2024-05-28T20:32:02.042076Z","shell.execute_reply.started":"2024-05-28T20:32:02.035529Z","shell.execute_reply":"2024-05-28T20:32:02.040187Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=20, stratify=Y)\n","metadata":{"id":"w-2tL4uR0rR6","papermill":{"duration":0.17901,"end_time":"2024-05-15T03:40:00.304649","exception":false,"start_time":"2024-05-15T03:40:00.125639","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-28T20:32:02.043850Z","iopub.execute_input":"2024-05-28T20:32:02.044264Z","iopub.status.idle":"2024-05-28T20:32:02.181903Z","shell.execute_reply.started":"2024-05-28T20:32:02.044231Z","shell.execute_reply":"2024-05-28T20:32:02.180798Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"Let's implement KNN","metadata":{"id":"ZWzMjrlu1iFL","papermill":{"duration":0.015556,"end_time":"2024-05-15T03:40:00.336065","exception":false,"start_time":"2024-05-15T03:40:00.320509","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\ntest_score = []\ntrain_score = []\nfor i in range(5,15):\n    neigh = KNeighborsClassifier(n_neighbors=i)\n    neigh.fit(X_train, y_train)\n    train_score.append(neigh.score(X_train,y_train))\n    test_score.append(neigh.score(X_test,y_test))","metadata":{"id":"o_YSWzUc9qPJ","papermill":{"duration":1.000929,"end_time":"2024-05-15T03:40:01.353347","exception":false,"start_time":"2024-05-15T03:40:00.352418","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-28T20:32:02.183584Z","iopub.execute_input":"2024-05-28T20:32:02.184195Z","iopub.status.idle":"2024-05-28T20:32:03.236971Z","shell.execute_reply.started":"2024-05-28T20:32:02.184160Z","shell.execute_reply":"2024-05-28T20:32:03.235977Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"print('Max train_scores is ' + str(max(train_score)*100) + ' for k = '+\n      str(train_score.index(max(train_score))+5))","metadata":{"id":"3JuDuztv1xWs","outputId":"2b650173-8a87-4a1f-dd8b-ef00e507ce4e","papermill":{"duration":0.026518,"end_time":"2024-05-15T03:40:01.395931","exception":false,"start_time":"2024-05-15T03:40:01.369413","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-28T20:32:03.238442Z","iopub.execute_input":"2024-05-28T20:32:03.238997Z","iopub.status.idle":"2024-05-28T20:32:03.245826Z","shell.execute_reply.started":"2024-05-28T20:32:03.238966Z","shell.execute_reply":"2024-05-28T20:32:03.244749Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Max train_scores is 85.66775244299674 for k = 5\n","output_type":"stream"}]},{"cell_type":"code","source":"print('Max test_scores is ' + str(max(test_score)*100) + \"k =\"+\n      str(test_score.index(max(test_score))+5))","metadata":{"id":"Iz4yLuzf41AY","outputId":"66337571-0695-495d-b060-13dc89ad541c","papermill":{"duration":0.027403,"end_time":"2024-05-15T03:40:01.438909","exception":false,"start_time":"2024-05-15T03:40:01.411506","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-28T20:32:03.247547Z","iopub.execute_input":"2024-05-28T20:32:03.248151Z","iopub.status.idle":"2024-05-28T20:32:03.261809Z","shell.execute_reply.started":"2024-05-28T20:32:03.248109Z","shell.execute_reply":"2024-05-28T20:32:03.260795Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Max test_scores is 87.01298701298701k =13\n","output_type":"stream"}]},{"cell_type":"markdown","source":"###Logistic regression","metadata":{"id":"E0e1Z_F6PT-k","papermill":{"duration":0.016545,"end_time":"2024-05-15T03:40:01.472144","exception":false,"start_time":"2024-05-15T03:40:01.455599","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Lets try Logistic regression now\nfrom sklearn.linear_model import LogisticRegression\nlog_model = LogisticRegression(random_state=20, penalty='l2').fit(X_train, y_train)\nlog_pred=log_model.predict(X_test)\nlog_model.score(X_test, y_test)","metadata":{"id":"acvWDr2k-983","outputId":"1318f3e9-bef0-4864-ca90-188788d88bb3","papermill":{"duration":0.046376,"end_time":"2024-05-15T03:40:01.535025","exception":false,"start_time":"2024-05-15T03:40:01.488649","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-28T20:32:03.263469Z","iopub.execute_input":"2024-05-28T20:32:03.264273Z","iopub.status.idle":"2024-05-28T20:32:03.299282Z","shell.execute_reply.started":"2024-05-28T20:32:03.264239Z","shell.execute_reply":"2024-05-28T20:32:03.298086Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"0.8311688311688312"},"metadata":{}}]},{"cell_type":"markdown","source":"###SVC","metadata":{"id":"g4FG8fltpvRr","papermill":{"duration":0.015593,"end_time":"2024-05-15T03:40:01.566734","exception":false,"start_time":"2024-05-15T03:40:01.551141","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from sklearn import svm\nsvm_model = svm.SVC().fit(X_train, y_train)\nsvm_pred=svm_model.predict(X_test)\nsvm_model.score(X_test, y_test)","metadata":{"id":"C-VvIB1wovy2","outputId":"b8a75210-3620-474e-bf9a-e9680e67a1e7","papermill":{"duration":0.053264,"end_time":"2024-05-15T03:40:01.635899","exception":false,"start_time":"2024-05-15T03:40:01.582635","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-28T20:32:03.300812Z","iopub.execute_input":"2024-05-28T20:32:03.301374Z","iopub.status.idle":"2024-05-28T20:32:03.336040Z","shell.execute_reply.started":"2024-05-28T20:32:03.301342Z","shell.execute_reply":"2024-05-28T20:32:03.334784Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"0.8896103896103896"},"metadata":{}}]},{"cell_type":"markdown","source":"Model Accuracy Confirmation","metadata":{"id":"7clERX5Bs0fs","papermill":{"duration":0.016398,"end_time":"2024-05-15T03:40:01.668569","exception":false,"start_time":"2024-05-15T03:40:01.652171","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def model_pref(pred, y_test):\n  cmp = []\n  for i, j in zip(pred, y_test):\n    if i == j:\n      cmp.append(1)\n    else:\n      cmp.append(0)\n  return cmp","metadata":{"id":"e03EGUNZpqZE","papermill":{"duration":0.028396,"end_time":"2024-05-15T03:40:01.713418","exception":false,"start_time":"2024-05-15T03:40:01.685022","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-28T20:32:03.337795Z","iopub.execute_input":"2024-05-28T20:32:03.338186Z","iopub.status.idle":"2024-05-28T20:32:03.345713Z","shell.execute_reply.started":"2024-05-28T20:32:03.338155Z","shell.execute_reply":"2024-05-28T20:32:03.344411Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"cmp =model_pref(svm_pred, y_test)","metadata":{"id":"B95nMn86r-pj","papermill":{"duration":0.025697,"end_time":"2024-05-15T03:40:01.756728","exception":false,"start_time":"2024-05-15T03:40:01.731031","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-28T20:32:03.347732Z","iopub.execute_input":"2024-05-28T20:32:03.348998Z","iopub.status.idle":"2024-05-28T20:32:03.362856Z","shell.execute_reply.started":"2024-05-28T20:32:03.348960Z","shell.execute_reply":"2024-05-28T20:32:03.361372Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"print(\"Model Accuracy Confirmation: \" +str(cmp.count(1)/len(y_test)))","metadata":{"id":"Ua0naiLPsFfP","outputId":"9363c38e-0c0e-4572-c77a-247315c0d2ff","papermill":{"duration":0.026586,"end_time":"2024-05-15T03:40:01.799701","exception":false,"start_time":"2024-05-15T03:40:01.773115","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-28T20:32:03.364775Z","iopub.execute_input":"2024-05-28T20:32:03.366679Z","iopub.status.idle":"2024-05-28T20:32:03.381795Z","shell.execute_reply.started":"2024-05-28T20:32:03.366631Z","shell.execute_reply":"2024-05-28T20:32:03.380156Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Model Accuracy Confirmation: 0.8896103896103896\n","output_type":"stream"}]},{"cell_type":"markdown","source":"###RandomForest","metadata":{"id":"OoV90AvltAnc","papermill":{"duration":0.016829,"end_time":"2024-05-15T03:40:01.833178","exception":false,"start_time":"2024-05-15T03:40:01.816349","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrf_model = RandomForestClassifier(max_depth=2, random_state=20).fit(X_train, y_train)\nrf_pred=rf_model.predict(X_test)\nrf_model.score(X_test, y_test)","metadata":{"id":"bPBpZBCAsbqT","outputId":"1f3e112e-663a-4f43-da8b-de1777c67fe7","papermill":{"duration":0.463701,"end_time":"2024-05-15T03:40:02.314223","exception":false,"start_time":"2024-05-15T03:40:01.850522","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-28T20:32:03.384197Z","iopub.execute_input":"2024-05-28T20:32:03.385194Z","iopub.status.idle":"2024-05-28T20:32:03.799994Z","shell.execute_reply.started":"2024-05-28T20:32:03.385144Z","shell.execute_reply":"2024-05-28T20:32:03.799134Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"0.8571428571428571"},"metadata":{}}]},{"cell_type":"markdown","source":"###Training Deep neural network","metadata":{"id":"tEiQGgeOPbGF","papermill":{"duration":0.017017,"end_time":"2024-05-15T03:40:02.349362","exception":false,"start_time":"2024-05-15T03:40:02.332345","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import tensorflow as tf\ndef build_model():\n  model = tf.keras.Sequential([\n      tf.keras.layers.Dense(8, activation = 'relu', input_shape=[len(X_train.keys())]),\n      tf.keras.layers.Dense(4, activation = 'relu'),\n      tf.keras.layers.Dense(2, activation = 'relu'),\n      tf.keras.layers.Dense(1, activation = 'sigmoid')\n\n  ])\n\n\n  optimizer = tf.keras.optimizers.Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-07)\n  model.compile(loss= 'binary_crossentropy', optimizer = optimizer, metrics = ['accuracy'])\n  return model\nneural_model = build_model()","metadata":{"id":"9PjcaiQUtLUM","papermill":{"duration":15.232609,"end_time":"2024-05-15T03:40:17.603448","exception":false,"start_time":"2024-05-15T03:40:02.370839","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-28T20:32:03.801862Z","iopub.execute_input":"2024-05-28T20:32:03.802638Z","iopub.status.idle":"2024-05-28T20:32:18.163001Z","shell.execute_reply.started":"2024-05-28T20:32:03.802591Z","shell.execute_reply":"2024-05-28T20:32:18.161586Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"2024-05-28 20:32:06.054852: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-28 20:32:06.054982: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-28 20:32:06.182995: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"}]},{"cell_type":"code","source":"neural_model.summary()","metadata":{"id":"ngQMjd8BvRvN","outputId":"b683c9ed-da6a-417e-b3e7-4406e67cee19","papermill":{"duration":0.047158,"end_time":"2024-05-15T03:40:17.667980","exception":false,"start_time":"2024-05-15T03:40:17.620822","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-28T20:32:18.164859Z","iopub.execute_input":"2024-05-28T20:32:18.165501Z","iopub.status.idle":"2024-05-28T20:32:18.199920Z","shell.execute_reply.started":"2024-05-28T20:32:18.165469Z","shell.execute_reply":"2024-05-28T20:32:18.198900Z"},"trusted":true},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │            \u001b[38;5;34m72\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │            \u001b[38;5;34m36\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │            \u001b[38;5;34m10\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m3\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m121\u001b[0m (484.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">121</span> (484.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m121\u001b[0m (484.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">121</span> (484.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"markdown","source":"Fit Neural model on dataset.","metadata":{"id":"vYvc1dEmHo9X","papermill":{"duration":0.01832,"end_time":"2024-05-15T03:40:17.704526","exception":false,"start_time":"2024-05-15T03:40:17.686206","status":"completed"},"tags":[]}},{"cell_type":"code","source":"neural_pred = neural_model.fit(X_train, y_train, validation_split=0.1, verbose=2, epochs=550)","metadata":{"id":"s7w0aAhJG3-f","outputId":"c82ba12c-e4f5-4da5-c345-b20af5761a2a","papermill":{"duration":119.348539,"end_time":"2024-05-15T03:42:17.071948","exception":false,"start_time":"2024-05-15T03:40:17.723409","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-28T20:32:18.201237Z","iopub.execute_input":"2024-05-28T20:32:18.203081Z","iopub.status.idle":"2024-05-28T20:33:26.651758Z","shell.execute_reply.started":"2024-05-28T20:32:18.203049Z","shell.execute_reply":"2024-05-28T20:33:26.650456Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Epoch 1/550\n18/18 - 2s - 100ms/step - accuracy: 0.5688 - loss: 0.6987 - val_accuracy: 0.8226 - val_loss: 0.6323\nEpoch 2/550\n18/18 - 0s - 5ms/step - accuracy: 0.7337 - loss: 0.6332 - val_accuracy: 0.8548 - val_loss: 0.5780\nEpoch 3/550\n18/18 - 0s - 5ms/step - accuracy: 0.7627 - loss: 0.6034 - val_accuracy: 0.8387 - val_loss: 0.5442\nEpoch 4/550\n18/18 - 0s - 8ms/step - accuracy: 0.7754 - loss: 0.5708 - val_accuracy: 0.8065 - val_loss: 0.5161\nEpoch 5/550\n18/18 - 0s - 8ms/step - accuracy: 0.7862 - loss: 0.5496 - val_accuracy: 0.8226 - val_loss: 0.4862\nEpoch 6/550\n18/18 - 0s - 8ms/step - accuracy: 0.7808 - loss: 0.5275 - val_accuracy: 0.8387 - val_loss: 0.4668\nEpoch 7/550\n18/18 - 0s - 8ms/step - accuracy: 0.8043 - loss: 0.5046 - val_accuracy: 0.8710 - val_loss: 0.4332\nEpoch 8/550\n18/18 - 0s - 7ms/step - accuracy: 0.8152 - loss: 0.4779 - val_accuracy: 0.8710 - val_loss: 0.4008\nEpoch 9/550\n18/18 - 0s - 5ms/step - accuracy: 0.8170 - loss: 0.4597 - val_accuracy: 0.8871 - val_loss: 0.3733\nEpoch 10/550\n18/18 - 0s - 9ms/step - accuracy: 0.8370 - loss: 0.4311 - val_accuracy: 0.9194 - val_loss: 0.3587\nEpoch 11/550\n18/18 - 0s - 5ms/step - accuracy: 0.8605 - loss: 0.4102 - val_accuracy: 0.9194 - val_loss: 0.3202\nEpoch 12/550\n18/18 - 0s - 5ms/step - accuracy: 0.8587 - loss: 0.3918 - val_accuracy: 0.9032 - val_loss: 0.3099\nEpoch 13/550\n18/18 - 0s - 8ms/step - accuracy: 0.8605 - loss: 0.3822 - val_accuracy: 0.9194 - val_loss: 0.3035\nEpoch 14/550\n18/18 - 0s - 7ms/step - accuracy: 0.8678 - loss: 0.3701 - val_accuracy: 0.9194 - val_loss: 0.2895\nEpoch 15/550\n18/18 - 0s - 5ms/step - accuracy: 0.8696 - loss: 0.3579 - val_accuracy: 0.9194 - val_loss: 0.2844\nEpoch 16/550\n18/18 - 0s - 5ms/step - accuracy: 0.8678 - loss: 0.3535 - val_accuracy: 0.9194 - val_loss: 0.2770\nEpoch 17/550\n18/18 - 0s - 5ms/step - accuracy: 0.8696 - loss: 0.3545 - val_accuracy: 0.9032 - val_loss: 0.2891\nEpoch 18/550\n18/18 - 0s - 5ms/step - accuracy: 0.8678 - loss: 0.3510 - val_accuracy: 0.9194 - val_loss: 0.2549\nEpoch 19/550\n18/18 - 0s - 8ms/step - accuracy: 0.8696 - loss: 0.3417 - val_accuracy: 0.9032 - val_loss: 0.2746\nEpoch 20/550\n18/18 - 0s - 5ms/step - accuracy: 0.8714 - loss: 0.3342 - val_accuracy: 0.9194 - val_loss: 0.2616\nEpoch 21/550\n18/18 - 0s - 5ms/step - accuracy: 0.8750 - loss: 0.3308 - val_accuracy: 0.9032 - val_loss: 0.2768\nEpoch 22/550\n18/18 - 0s - 4ms/step - accuracy: 0.8641 - loss: 0.3381 - val_accuracy: 0.9194 - val_loss: 0.2653\nEpoch 23/550\n18/18 - 0s - 8ms/step - accuracy: 0.8750 - loss: 0.3236 - val_accuracy: 0.9194 - val_loss: 0.2582\nEpoch 24/550\n18/18 - 0s - 5ms/step - accuracy: 0.8714 - loss: 0.3243 - val_accuracy: 0.9194 - val_loss: 0.2494\nEpoch 25/550\n18/18 - 0s - 8ms/step - accuracy: 0.8768 - loss: 0.3228 - val_accuracy: 0.9032 - val_loss: 0.2708\nEpoch 26/550\n18/18 - 0s - 5ms/step - accuracy: 0.8841 - loss: 0.3216 - val_accuracy: 0.9194 - val_loss: 0.2541\nEpoch 27/550\n18/18 - 0s - 5ms/step - accuracy: 0.8678 - loss: 0.3080 - val_accuracy: 0.9194 - val_loss: 0.2524\nEpoch 28/550\n18/18 - 0s - 9ms/step - accuracy: 0.8877 - loss: 0.3057 - val_accuracy: 0.9194 - val_loss: 0.2500\nEpoch 29/550\n18/18 - 0s - 6ms/step - accuracy: 0.8804 - loss: 0.3024 - val_accuracy: 0.9194 - val_loss: 0.2410\nEpoch 30/550\n18/18 - 0s - 8ms/step - accuracy: 0.8859 - loss: 0.2964 - val_accuracy: 0.9194 - val_loss: 0.2507\nEpoch 31/550\n18/18 - 0s - 5ms/step - accuracy: 0.8931 - loss: 0.2987 - val_accuracy: 0.8871 - val_loss: 0.2568\nEpoch 32/550\n18/18 - 0s - 5ms/step - accuracy: 0.8913 - loss: 0.2931 - val_accuracy: 0.9194 - val_loss: 0.2635\nEpoch 33/550\n18/18 - 0s - 5ms/step - accuracy: 0.8913 - loss: 0.2941 - val_accuracy: 0.9032 - val_loss: 0.2415\nEpoch 34/550\n18/18 - 0s - 4ms/step - accuracy: 0.8877 - loss: 0.2880 - val_accuracy: 0.9032 - val_loss: 0.2525\nEpoch 35/550\n18/18 - 0s - 5ms/step - accuracy: 0.8841 - loss: 0.2894 - val_accuracy: 0.9032 - val_loss: 0.2460\nEpoch 36/550\n18/18 - 0s - 8ms/step - accuracy: 0.8913 - loss: 0.2938 - val_accuracy: 0.8871 - val_loss: 0.2808\nEpoch 37/550\n18/18 - 0s - 9ms/step - accuracy: 0.8986 - loss: 0.2753 - val_accuracy: 0.9032 - val_loss: 0.2323\nEpoch 38/550\n18/18 - 0s - 7ms/step - accuracy: 0.8895 - loss: 0.2766 - val_accuracy: 0.8871 - val_loss: 0.2682\nEpoch 39/550\n18/18 - 0s - 7ms/step - accuracy: 0.8931 - loss: 0.2830 - val_accuracy: 0.8871 - val_loss: 0.2537\nEpoch 40/550\n18/18 - 0s - 5ms/step - accuracy: 0.8913 - loss: 0.2827 - val_accuracy: 0.9032 - val_loss: 0.2622\nEpoch 41/550\n18/18 - 0s - 5ms/step - accuracy: 0.8931 - loss: 0.2742 - val_accuracy: 0.9194 - val_loss: 0.2441\nEpoch 42/550\n18/18 - 0s - 5ms/step - accuracy: 0.8913 - loss: 0.2748 - val_accuracy: 0.8548 - val_loss: 0.2710\nEpoch 43/550\n18/18 - 0s - 8ms/step - accuracy: 0.8931 - loss: 0.2762 - val_accuracy: 0.9032 - val_loss: 0.2654\nEpoch 44/550\n18/18 - 0s - 8ms/step - accuracy: 0.9004 - loss: 0.2720 - val_accuracy: 0.8548 - val_loss: 0.2437\nEpoch 45/550\n18/18 - 0s - 6ms/step - accuracy: 0.8949 - loss: 0.2745 - val_accuracy: 0.8871 - val_loss: 0.2864\nEpoch 46/550\n18/18 - 0s - 5ms/step - accuracy: 0.9004 - loss: 0.2732 - val_accuracy: 0.8871 - val_loss: 0.2637\nEpoch 47/550\n18/18 - 0s - 8ms/step - accuracy: 0.8949 - loss: 0.2759 - val_accuracy: 0.8710 - val_loss: 0.2753\nEpoch 48/550\n18/18 - 0s - 5ms/step - accuracy: 0.8967 - loss: 0.2755 - val_accuracy: 0.9032 - val_loss: 0.2520\nEpoch 49/550\n18/18 - 0s - 8ms/step - accuracy: 0.8786 - loss: 0.3228 - val_accuracy: 0.8710 - val_loss: 0.3698\nEpoch 50/550\n18/18 - 0s - 5ms/step - accuracy: 0.8895 - loss: 0.2908 - val_accuracy: 0.8548 - val_loss: 0.2916\nEpoch 51/550\n18/18 - 0s - 7ms/step - accuracy: 0.8877 - loss: 0.2898 - val_accuracy: 0.8871 - val_loss: 0.2521\nEpoch 52/550\n18/18 - 0s - 8ms/step - accuracy: 0.8967 - loss: 0.2720 - val_accuracy: 0.9194 - val_loss: 0.2661\nEpoch 53/550\n18/18 - 0s - 8ms/step - accuracy: 0.8895 - loss: 0.2820 - val_accuracy: 0.8710 - val_loss: 0.2732\nEpoch 54/550\n18/18 - 0s - 8ms/step - accuracy: 0.8949 - loss: 0.2630 - val_accuracy: 0.8871 - val_loss: 0.2781\nEpoch 55/550\n18/18 - 0s - 8ms/step - accuracy: 0.9076 - loss: 0.2622 - val_accuracy: 0.8548 - val_loss: 0.2683\nEpoch 56/550\n18/18 - 0s - 6ms/step - accuracy: 0.9130 - loss: 0.2607 - val_accuracy: 0.9032 - val_loss: 0.2765\nEpoch 57/550\n18/18 - 0s - 7ms/step - accuracy: 0.9094 - loss: 0.2608 - val_accuracy: 0.8387 - val_loss: 0.2957\nEpoch 58/550\n18/18 - 0s - 8ms/step - accuracy: 0.9149 - loss: 0.2571 - val_accuracy: 0.8548 - val_loss: 0.2954\nEpoch 59/550\n18/18 - 0s - 5ms/step - accuracy: 0.9094 - loss: 0.2594 - val_accuracy: 0.8548 - val_loss: 0.2818\nEpoch 60/550\n18/18 - 0s - 8ms/step - accuracy: 0.9076 - loss: 0.2648 - val_accuracy: 0.8548 - val_loss: 0.2842\nEpoch 61/550\n18/18 - 0s - 5ms/step - accuracy: 0.9022 - loss: 0.2586 - val_accuracy: 0.8387 - val_loss: 0.2736\nEpoch 62/550\n18/18 - 0s - 5ms/step - accuracy: 0.9004 - loss: 0.2602 - val_accuracy: 0.8548 - val_loss: 0.2846\nEpoch 63/550\n18/18 - 0s - 5ms/step - accuracy: 0.9004 - loss: 0.2631 - val_accuracy: 0.8710 - val_loss: 0.2962\nEpoch 64/550\n18/18 - 0s - 6ms/step - accuracy: 0.9130 - loss: 0.2582 - val_accuracy: 0.8871 - val_loss: 0.2778\nEpoch 65/550\n18/18 - 0s - 6ms/step - accuracy: 0.9022 - loss: 0.2614 - val_accuracy: 0.8387 - val_loss: 0.2984\nEpoch 66/550\n18/18 - 0s - 4ms/step - accuracy: 0.9058 - loss: 0.2569 - val_accuracy: 0.8548 - val_loss: 0.3083\nEpoch 67/550\n18/18 - 0s - 6ms/step - accuracy: 0.9076 - loss: 0.2522 - val_accuracy: 0.8710 - val_loss: 0.3148\nEpoch 68/550\n18/18 - 0s - 5ms/step - accuracy: 0.9094 - loss: 0.2543 - val_accuracy: 0.8548 - val_loss: 0.2934\nEpoch 69/550\n18/18 - 0s - 8ms/step - accuracy: 0.9058 - loss: 0.2575 - val_accuracy: 0.8871 - val_loss: 0.3205\nEpoch 70/550\n18/18 - 0s - 7ms/step - accuracy: 0.9094 - loss: 0.2560 - val_accuracy: 0.8548 - val_loss: 0.2989\nEpoch 71/550\n18/18 - 0s - 5ms/step - accuracy: 0.9076 - loss: 0.2543 - val_accuracy: 0.8710 - val_loss: 0.3379\nEpoch 72/550\n18/18 - 0s - 5ms/step - accuracy: 0.9112 - loss: 0.2519 - val_accuracy: 0.8548 - val_loss: 0.3206\nEpoch 73/550\n18/18 - 0s - 6ms/step - accuracy: 0.9149 - loss: 0.2503 - val_accuracy: 0.8226 - val_loss: 0.3579\nEpoch 74/550\n18/18 - 0s - 5ms/step - accuracy: 0.9040 - loss: 0.2510 - val_accuracy: 0.8387 - val_loss: 0.3170\nEpoch 75/550\n18/18 - 0s - 4ms/step - accuracy: 0.9185 - loss: 0.2462 - val_accuracy: 0.8548 - val_loss: 0.3200\nEpoch 76/550\n18/18 - 0s - 5ms/step - accuracy: 0.9058 - loss: 0.2555 - val_accuracy: 0.8387 - val_loss: 0.3437\nEpoch 77/550\n18/18 - 0s - 8ms/step - accuracy: 0.9112 - loss: 0.2536 - val_accuracy: 0.8710 - val_loss: 0.3261\nEpoch 78/550\n18/18 - 0s - 8ms/step - accuracy: 0.9058 - loss: 0.2562 - val_accuracy: 0.8226 - val_loss: 0.3340\nEpoch 79/550\n18/18 - 0s - 5ms/step - accuracy: 0.9094 - loss: 0.2529 - val_accuracy: 0.8710 - val_loss: 0.3437\nEpoch 80/550\n18/18 - 0s - 5ms/step - accuracy: 0.9094 - loss: 0.2440 - val_accuracy: 0.8065 - val_loss: 0.3587\nEpoch 81/550\n18/18 - 0s - 5ms/step - accuracy: 0.9094 - loss: 0.2490 - val_accuracy: 0.8548 - val_loss: 0.3634\nEpoch 82/550\n18/18 - 0s - 5ms/step - accuracy: 0.9094 - loss: 0.2448 - val_accuracy: 0.8226 - val_loss: 0.3568\nEpoch 83/550\n18/18 - 0s - 5ms/step - accuracy: 0.9167 - loss: 0.2493 - val_accuracy: 0.8710 - val_loss: 0.3329\nEpoch 84/550\n18/18 - 0s - 5ms/step - accuracy: 0.9112 - loss: 0.2479 - val_accuracy: 0.8387 - val_loss: 0.3241\nEpoch 85/550\n18/18 - 0s - 8ms/step - accuracy: 0.9004 - loss: 0.2667 - val_accuracy: 0.8548 - val_loss: 0.3506\nEpoch 86/550\n18/18 - 0s - 5ms/step - accuracy: 0.9076 - loss: 0.2615 - val_accuracy: 0.8387 - val_loss: 0.3395\nEpoch 87/550\n18/18 - 0s - 5ms/step - accuracy: 0.9149 - loss: 0.2469 - val_accuracy: 0.8871 - val_loss: 0.3117\nEpoch 88/550\n18/18 - 0s - 8ms/step - accuracy: 0.9130 - loss: 0.2422 - val_accuracy: 0.8387 - val_loss: 0.3425\nEpoch 89/550\n18/18 - 0s - 8ms/step - accuracy: 0.9112 - loss: 0.2434 - val_accuracy: 0.8226 - val_loss: 0.3746\nEpoch 90/550\n18/18 - 0s - 5ms/step - accuracy: 0.9130 - loss: 0.2432 - val_accuracy: 0.8871 - val_loss: 0.3649\nEpoch 91/550\n18/18 - 0s - 7ms/step - accuracy: 0.9112 - loss: 0.2458 - val_accuracy: 0.8226 - val_loss: 0.3761\nEpoch 92/550\n18/18 - 0s - 8ms/step - accuracy: 0.8967 - loss: 0.3267 - val_accuracy: 0.8548 - val_loss: 0.3425\nEpoch 93/550\n18/18 - 0s - 8ms/step - accuracy: 0.9040 - loss: 0.2853 - val_accuracy: 0.8226 - val_loss: 0.3146\nEpoch 94/550\n18/18 - 0s - 7ms/step - accuracy: 0.9076 - loss: 0.2723 - val_accuracy: 0.8387 - val_loss: 0.3487\nEpoch 95/550\n18/18 - 0s - 8ms/step - accuracy: 0.9022 - loss: 0.2727 - val_accuracy: 0.8548 - val_loss: 0.3076\nEpoch 96/550\n18/18 - 0s - 5ms/step - accuracy: 0.9112 - loss: 0.2683 - val_accuracy: 0.8387 - val_loss: 0.3503\nEpoch 97/550\n18/18 - 0s - 5ms/step - accuracy: 0.9130 - loss: 0.2588 - val_accuracy: 0.8226 - val_loss: 0.3503\nEpoch 98/550\n18/18 - 0s - 8ms/step - accuracy: 0.9149 - loss: 0.2530 - val_accuracy: 0.8226 - val_loss: 0.3924\nEpoch 99/550\n18/18 - 0s - 5ms/step - accuracy: 0.9149 - loss: 0.2492 - val_accuracy: 0.8065 - val_loss: 0.3398\nEpoch 100/550\n18/18 - 0s - 8ms/step - accuracy: 0.9112 - loss: 0.2462 - val_accuracy: 0.8226 - val_loss: 0.3866\nEpoch 101/550\n18/18 - 0s - 8ms/step - accuracy: 0.9058 - loss: 0.2522 - val_accuracy: 0.8226 - val_loss: 0.3897\nEpoch 102/550\n18/18 - 0s - 5ms/step - accuracy: 0.9185 - loss: 0.2424 - val_accuracy: 0.8387 - val_loss: 0.3738\nEpoch 103/550\n18/18 - 0s - 7ms/step - accuracy: 0.9203 - loss: 0.2385 - val_accuracy: 0.8226 - val_loss: 0.3741\nEpoch 104/550\n18/18 - 0s - 7ms/step - accuracy: 0.9185 - loss: 0.2422 - val_accuracy: 0.8387 - val_loss: 0.3479\nEpoch 105/550\n18/18 - 0s - 8ms/step - accuracy: 0.9167 - loss: 0.2415 - val_accuracy: 0.8387 - val_loss: 0.3553\nEpoch 106/550\n18/18 - 0s - 8ms/step - accuracy: 0.9167 - loss: 0.2394 - val_accuracy: 0.8710 - val_loss: 0.3374\nEpoch 107/550\n18/18 - 0s - 5ms/step - accuracy: 0.9094 - loss: 0.2472 - val_accuracy: 0.8387 - val_loss: 0.3146\nEpoch 108/550\n18/18 - 0s - 8ms/step - accuracy: 0.9149 - loss: 0.2389 - val_accuracy: 0.8387 - val_loss: 0.3643\nEpoch 109/550\n18/18 - 0s - 5ms/step - accuracy: 0.9094 - loss: 0.2651 - val_accuracy: 0.8226 - val_loss: 0.3602\nEpoch 110/550\n18/18 - 0s - 5ms/step - accuracy: 0.8986 - loss: 0.2596 - val_accuracy: 0.8387 - val_loss: 0.3748\nEpoch 111/550\n18/18 - 0s - 5ms/step - accuracy: 0.9130 - loss: 0.2382 - val_accuracy: 0.8387 - val_loss: 0.3827\nEpoch 112/550\n18/18 - 0s - 7ms/step - accuracy: 0.9076 - loss: 0.2398 - val_accuracy: 0.8548 - val_loss: 0.3428\nEpoch 113/550\n18/18 - 0s - 4ms/step - accuracy: 0.9167 - loss: 0.2316 - val_accuracy: 0.8548 - val_loss: 0.3770\nEpoch 114/550\n18/18 - 0s - 5ms/step - accuracy: 0.9221 - loss: 0.2299 - val_accuracy: 0.8387 - val_loss: 0.3511\nEpoch 115/550\n18/18 - 0s - 7ms/step - accuracy: 0.9203 - loss: 0.2341 - val_accuracy: 0.8387 - val_loss: 0.3953\nEpoch 116/550\n18/18 - 0s - 8ms/step - accuracy: 0.9185 - loss: 0.2311 - val_accuracy: 0.8548 - val_loss: 0.4091\nEpoch 117/550\n18/18 - 0s - 7ms/step - accuracy: 0.9239 - loss: 0.2293 - val_accuracy: 0.8387 - val_loss: 0.4224\nEpoch 118/550\n18/18 - 0s - 8ms/step - accuracy: 0.9221 - loss: 0.2334 - val_accuracy: 0.8548 - val_loss: 0.3649\nEpoch 119/550\n18/18 - 0s - 5ms/step - accuracy: 0.9185 - loss: 0.2352 - val_accuracy: 0.8387 - val_loss: 0.3589\nEpoch 120/550\n18/18 - 0s - 7ms/step - accuracy: 0.9203 - loss: 0.2289 - val_accuracy: 0.8548 - val_loss: 0.3964\nEpoch 121/550\n18/18 - 0s - 5ms/step - accuracy: 0.9203 - loss: 0.2279 - val_accuracy: 0.8387 - val_loss: 0.3514\nEpoch 122/550\n18/18 - 0s - 8ms/step - accuracy: 0.9203 - loss: 0.2399 - val_accuracy: 0.8548 - val_loss: 0.4138\nEpoch 123/550\n18/18 - 0s - 4ms/step - accuracy: 0.9040 - loss: 0.2559 - val_accuracy: 0.8548 - val_loss: 0.3827\nEpoch 124/550\n18/18 - 0s - 8ms/step - accuracy: 0.9040 - loss: 0.2603 - val_accuracy: 0.8548 - val_loss: 0.4110\nEpoch 125/550\n18/18 - 0s - 8ms/step - accuracy: 0.9149 - loss: 0.2467 - val_accuracy: 0.8387 - val_loss: 0.4213\nEpoch 126/550\n18/18 - 0s - 4ms/step - accuracy: 0.9149 - loss: 0.2511 - val_accuracy: 0.8548 - val_loss: 0.3225\nEpoch 127/550\n18/18 - 0s - 4ms/step - accuracy: 0.9149 - loss: 0.2347 - val_accuracy: 0.8548 - val_loss: 0.4345\nEpoch 128/550\n18/18 - 0s - 8ms/step - accuracy: 0.9185 - loss: 0.2313 - val_accuracy: 0.8387 - val_loss: 0.4138\nEpoch 129/550\n18/18 - 0s - 8ms/step - accuracy: 0.9239 - loss: 0.2261 - val_accuracy: 0.8387 - val_loss: 0.4056\nEpoch 130/550\n18/18 - 0s - 7ms/step - accuracy: 0.9221 - loss: 0.2266 - val_accuracy: 0.8387 - val_loss: 0.4008\nEpoch 131/550\n18/18 - 0s - 5ms/step - accuracy: 0.9275 - loss: 0.2261 - val_accuracy: 0.8387 - val_loss: 0.4122\nEpoch 132/550\n18/18 - 0s - 5ms/step - accuracy: 0.9203 - loss: 0.2332 - val_accuracy: 0.8387 - val_loss: 0.3878\nEpoch 133/550\n18/18 - 0s - 5ms/step - accuracy: 0.9221 - loss: 0.2300 - val_accuracy: 0.8387 - val_loss: 0.4068\nEpoch 134/550\n18/18 - 0s - 5ms/step - accuracy: 0.9239 - loss: 0.2238 - val_accuracy: 0.8387 - val_loss: 0.4066\nEpoch 135/550\n18/18 - 0s - 4ms/step - accuracy: 0.9221 - loss: 0.2353 - val_accuracy: 0.8548 - val_loss: 0.3887\nEpoch 136/550\n18/18 - 0s - 8ms/step - accuracy: 0.9167 - loss: 0.2336 - val_accuracy: 0.8387 - val_loss: 0.3974\nEpoch 137/550\n18/18 - 0s - 4ms/step - accuracy: 0.9275 - loss: 0.2254 - val_accuracy: 0.8387 - val_loss: 0.4046\nEpoch 138/550\n18/18 - 0s - 5ms/step - accuracy: 0.9221 - loss: 0.2228 - val_accuracy: 0.8387 - val_loss: 0.4098\nEpoch 139/550\n18/18 - 0s - 7ms/step - accuracy: 0.9293 - loss: 0.2173 - val_accuracy: 0.8387 - val_loss: 0.4293\nEpoch 140/550\n18/18 - 0s - 5ms/step - accuracy: 0.9257 - loss: 0.2196 - val_accuracy: 0.8387 - val_loss: 0.4244\nEpoch 141/550\n18/18 - 0s - 4ms/step - accuracy: 0.9293 - loss: 0.2187 - val_accuracy: 0.8387 - val_loss: 0.3867\nEpoch 142/550\n18/18 - 0s - 8ms/step - accuracy: 0.9293 - loss: 0.2183 - val_accuracy: 0.8387 - val_loss: 0.4085\nEpoch 143/550\n18/18 - 0s - 8ms/step - accuracy: 0.9330 - loss: 0.2142 - val_accuracy: 0.8387 - val_loss: 0.3901\nEpoch 144/550\n18/18 - 0s - 5ms/step - accuracy: 0.9275 - loss: 0.2221 - val_accuracy: 0.8387 - val_loss: 0.3990\nEpoch 145/550\n18/18 - 0s - 5ms/step - accuracy: 0.9239 - loss: 0.2189 - val_accuracy: 0.8387 - val_loss: 0.4033\nEpoch 146/550\n18/18 - 0s - 5ms/step - accuracy: 0.9257 - loss: 0.2193 - val_accuracy: 0.8387 - val_loss: 0.4321\nEpoch 147/550\n18/18 - 0s - 5ms/step - accuracy: 0.9203 - loss: 0.2226 - val_accuracy: 0.8387 - val_loss: 0.4358\nEpoch 148/550\n18/18 - 0s - 5ms/step - accuracy: 0.9293 - loss: 0.2157 - val_accuracy: 0.8387 - val_loss: 0.4278\nEpoch 149/550\n18/18 - 0s - 5ms/step - accuracy: 0.9330 - loss: 0.2127 - val_accuracy: 0.8387 - val_loss: 0.4406\nEpoch 150/550\n18/18 - 0s - 5ms/step - accuracy: 0.9293 - loss: 0.2114 - val_accuracy: 0.8387 - val_loss: 0.4018\nEpoch 151/550\n18/18 - 0s - 7ms/step - accuracy: 0.9312 - loss: 0.2174 - val_accuracy: 0.8387 - val_loss: 0.4562\nEpoch 152/550\n18/18 - 0s - 5ms/step - accuracy: 0.9293 - loss: 0.2121 - val_accuracy: 0.8387 - val_loss: 0.4166\nEpoch 153/550\n18/18 - 0s - 8ms/step - accuracy: 0.9257 - loss: 0.2217 - val_accuracy: 0.8387 - val_loss: 0.4803\nEpoch 154/550\n18/18 - 0s - 5ms/step - accuracy: 0.9293 - loss: 0.2208 - val_accuracy: 0.8387 - val_loss: 0.4280\nEpoch 155/550\n18/18 - 0s - 5ms/step - accuracy: 0.9239 - loss: 0.2280 - val_accuracy: 0.8548 - val_loss: 0.4655\nEpoch 156/550\n18/18 - 0s - 8ms/step - accuracy: 0.9203 - loss: 0.2308 - val_accuracy: 0.8387 - val_loss: 0.4247\nEpoch 157/550\n18/18 - 0s - 9ms/step - accuracy: 0.9257 - loss: 0.2225 - val_accuracy: 0.8226 - val_loss: 0.4782\nEpoch 158/550\n18/18 - 0s - 5ms/step - accuracy: 0.9293 - loss: 0.2246 - val_accuracy: 0.8387 - val_loss: 0.4278\nEpoch 159/550\n18/18 - 0s - 5ms/step - accuracy: 0.9203 - loss: 0.2294 - val_accuracy: 0.8387 - val_loss: 0.4893\nEpoch 160/550\n18/18 - 0s - 8ms/step - accuracy: 0.9330 - loss: 0.2140 - val_accuracy: 0.8387 - val_loss: 0.4712\nEpoch 161/550\n18/18 - 0s - 8ms/step - accuracy: 0.9330 - loss: 0.2146 - val_accuracy: 0.8387 - val_loss: 0.4366\nEpoch 162/550\n18/18 - 0s - 4ms/step - accuracy: 0.9402 - loss: 0.2117 - val_accuracy: 0.8387 - val_loss: 0.4566\nEpoch 163/550\n18/18 - 0s - 5ms/step - accuracy: 0.9293 - loss: 0.2124 - val_accuracy: 0.8387 - val_loss: 0.4410\nEpoch 164/550\n18/18 - 0s - 5ms/step - accuracy: 0.9185 - loss: 0.2377 - val_accuracy: 0.8710 - val_loss: 0.3681\nEpoch 165/550\n18/18 - 0s - 5ms/step - accuracy: 0.9185 - loss: 0.2250 - val_accuracy: 0.8387 - val_loss: 0.4755\nEpoch 166/550\n18/18 - 0s - 8ms/step - accuracy: 0.9293 - loss: 0.2179 - val_accuracy: 0.8387 - val_loss: 0.4762\nEpoch 167/550\n18/18 - 0s - 8ms/step - accuracy: 0.9366 - loss: 0.2073 - val_accuracy: 0.8387 - val_loss: 0.4369\nEpoch 168/550\n18/18 - 0s - 5ms/step - accuracy: 0.9275 - loss: 0.2097 - val_accuracy: 0.8387 - val_loss: 0.4630\nEpoch 169/550\n18/18 - 0s - 5ms/step - accuracy: 0.9312 - loss: 0.2089 - val_accuracy: 0.8387 - val_loss: 0.4569\nEpoch 170/550\n18/18 - 0s - 8ms/step - accuracy: 0.9348 - loss: 0.2052 - val_accuracy: 0.8548 - val_loss: 0.4590\nEpoch 171/550\n18/18 - 0s - 5ms/step - accuracy: 0.9384 - loss: 0.2061 - val_accuracy: 0.8387 - val_loss: 0.4643\nEpoch 172/550\n18/18 - 0s - 7ms/step - accuracy: 0.9275 - loss: 0.2126 - val_accuracy: 0.8548 - val_loss: 0.4137\nEpoch 173/550\n18/18 - 0s - 5ms/step - accuracy: 0.9275 - loss: 0.2202 - val_accuracy: 0.8548 - val_loss: 0.5224\nEpoch 174/550\n18/18 - 0s - 8ms/step - accuracy: 0.9348 - loss: 0.2038 - val_accuracy: 0.8387 - val_loss: 0.4491\nEpoch 175/550\n18/18 - 0s - 5ms/step - accuracy: 0.9348 - loss: 0.2091 - val_accuracy: 0.8226 - val_loss: 0.5135\nEpoch 176/550\n18/18 - 0s - 7ms/step - accuracy: 0.9348 - loss: 0.2089 - val_accuracy: 0.8387 - val_loss: 0.5007\nEpoch 177/550\n18/18 - 0s - 4ms/step - accuracy: 0.9402 - loss: 0.2070 - val_accuracy: 0.8387 - val_loss: 0.4508\nEpoch 178/550\n18/18 - 0s - 5ms/step - accuracy: 0.9330 - loss: 0.2118 - val_accuracy: 0.8387 - val_loss: 0.5041\nEpoch 179/550\n18/18 - 0s - 5ms/step - accuracy: 0.9312 - loss: 0.2274 - val_accuracy: 0.8387 - val_loss: 0.4430\nEpoch 180/550\n18/18 - 0s - 4ms/step - accuracy: 0.9185 - loss: 0.2366 - val_accuracy: 0.8387 - val_loss: 0.5049\nEpoch 181/550\n18/18 - 0s - 8ms/step - accuracy: 0.9312 - loss: 0.2172 - val_accuracy: 0.8387 - val_loss: 0.5103\nEpoch 182/550\n18/18 - 0s - 6ms/step - accuracy: 0.9312 - loss: 0.2165 - val_accuracy: 0.8387 - val_loss: 0.4583\nEpoch 183/550\n18/18 - 0s - 6ms/step - accuracy: 0.9312 - loss: 0.2154 - val_accuracy: 0.8387 - val_loss: 0.4740\nEpoch 184/550\n18/18 - 0s - 7ms/step - accuracy: 0.9185 - loss: 0.2249 - val_accuracy: 0.8226 - val_loss: 0.4438\nEpoch 185/550\n18/18 - 0s - 8ms/step - accuracy: 0.9275 - loss: 0.2234 - val_accuracy: 0.8226 - val_loss: 0.5369\nEpoch 186/550\n18/18 - 0s - 5ms/step - accuracy: 0.9203 - loss: 0.2367 - val_accuracy: 0.8387 - val_loss: 0.4933\nEpoch 187/550\n18/18 - 0s - 5ms/step - accuracy: 0.9312 - loss: 0.2139 - val_accuracy: 0.8387 - val_loss: 0.4903\nEpoch 188/550\n18/18 - 0s - 5ms/step - accuracy: 0.9312 - loss: 0.2171 - val_accuracy: 0.8387 - val_loss: 0.4541\nEpoch 189/550\n18/18 - 0s - 7ms/step - accuracy: 0.9330 - loss: 0.2125 - val_accuracy: 0.8387 - val_loss: 0.5424\nEpoch 190/550\n18/18 - 0s - 5ms/step - accuracy: 0.9167 - loss: 0.2254 - val_accuracy: 0.8387 - val_loss: 0.4700\nEpoch 191/550\n18/18 - 0s - 5ms/step - accuracy: 0.9293 - loss: 0.2158 - val_accuracy: 0.8226 - val_loss: 0.5125\nEpoch 192/550\n18/18 - 0s - 5ms/step - accuracy: 0.9348 - loss: 0.2125 - val_accuracy: 0.8226 - val_loss: 0.5118\nEpoch 193/550\n18/18 - 0s - 5ms/step - accuracy: 0.9257 - loss: 0.2156 - val_accuracy: 0.8387 - val_loss: 0.4474\nEpoch 194/550\n18/18 - 0s - 8ms/step - accuracy: 0.9366 - loss: 0.2131 - val_accuracy: 0.8387 - val_loss: 0.4956\nEpoch 195/550\n18/18 - 0s - 8ms/step - accuracy: 0.9348 - loss: 0.2131 - val_accuracy: 0.8387 - val_loss: 0.4674\nEpoch 196/550\n18/18 - 0s - 5ms/step - accuracy: 0.9348 - loss: 0.2084 - val_accuracy: 0.8387 - val_loss: 0.4660\nEpoch 197/550\n18/18 - 0s - 8ms/step - accuracy: 0.9348 - loss: 0.2108 - val_accuracy: 0.8387 - val_loss: 0.5041\nEpoch 198/550\n18/18 - 0s - 5ms/step - accuracy: 0.9366 - loss: 0.2104 - val_accuracy: 0.8387 - val_loss: 0.4820\nEpoch 199/550\n18/18 - 0s - 4ms/step - accuracy: 0.9293 - loss: 0.2141 - val_accuracy: 0.8387 - val_loss: 0.4710\nEpoch 200/550\n18/18 - 0s - 9ms/step - accuracy: 0.9293 - loss: 0.2116 - val_accuracy: 0.8226 - val_loss: 0.4655\nEpoch 201/550\n18/18 - 0s - 8ms/step - accuracy: 0.9384 - loss: 0.2048 - val_accuracy: 0.8387 - val_loss: 0.4695\nEpoch 202/550\n18/18 - 0s - 7ms/step - accuracy: 0.9330 - loss: 0.2145 - val_accuracy: 0.8226 - val_loss: 0.5810\nEpoch 203/550\n18/18 - 0s - 7ms/step - accuracy: 0.9366 - loss: 0.2104 - val_accuracy: 0.8548 - val_loss: 0.4412\nEpoch 204/550\n18/18 - 0s - 7ms/step - accuracy: 0.9330 - loss: 0.2108 - val_accuracy: 0.8548 - val_loss: 0.5303\nEpoch 205/550\n18/18 - 0s - 8ms/step - accuracy: 0.9348 - loss: 0.2030 - val_accuracy: 0.8387 - val_loss: 0.4472\nEpoch 206/550\n18/18 - 0s - 8ms/step - accuracy: 0.9366 - loss: 0.2108 - val_accuracy: 0.8387 - val_loss: 0.5123\nEpoch 207/550\n18/18 - 0s - 5ms/step - accuracy: 0.9348 - loss: 0.2147 - val_accuracy: 0.8548 - val_loss: 0.5432\nEpoch 208/550\n18/18 - 0s - 8ms/step - accuracy: 0.9330 - loss: 0.2085 - val_accuracy: 0.8548 - val_loss: 0.4455\nEpoch 209/550\n18/18 - 0s - 8ms/step - accuracy: 0.9239 - loss: 0.2169 - val_accuracy: 0.8387 - val_loss: 0.5837\nEpoch 210/550\n18/18 - 0s - 7ms/step - accuracy: 0.9348 - loss: 0.2115 - val_accuracy: 0.8387 - val_loss: 0.4746\nEpoch 211/550\n18/18 - 0s - 8ms/step - accuracy: 0.9330 - loss: 0.2022 - val_accuracy: 0.8548 - val_loss: 0.4612\nEpoch 212/550\n18/18 - 0s - 5ms/step - accuracy: 0.9275 - loss: 0.2163 - val_accuracy: 0.8387 - val_loss: 0.4501\nEpoch 213/550\n18/18 - 0s - 8ms/step - accuracy: 0.9221 - loss: 0.2262 - val_accuracy: 0.8387 - val_loss: 0.5361\nEpoch 214/550\n18/18 - 0s - 5ms/step - accuracy: 0.9366 - loss: 0.2201 - val_accuracy: 0.8387 - val_loss: 0.5008\nEpoch 215/550\n18/18 - 0s - 8ms/step - accuracy: 0.9366 - loss: 0.2156 - val_accuracy: 0.8387 - val_loss: 0.5156\nEpoch 216/550\n18/18 - 0s - 8ms/step - accuracy: 0.9293 - loss: 0.2160 - val_accuracy: 0.8387 - val_loss: 0.4908\nEpoch 217/550\n18/18 - 0s - 7ms/step - accuracy: 0.9384 - loss: 0.2147 - val_accuracy: 0.8548 - val_loss: 0.5503\nEpoch 218/550\n18/18 - 0s - 7ms/step - accuracy: 0.9312 - loss: 0.2142 - val_accuracy: 0.8548 - val_loss: 0.4950\nEpoch 219/550\n18/18 - 0s - 8ms/step - accuracy: 0.9384 - loss: 0.2158 - val_accuracy: 0.8387 - val_loss: 0.5237\nEpoch 220/550\n18/18 - 0s - 7ms/step - accuracy: 0.9330 - loss: 0.2112 - val_accuracy: 0.8387 - val_loss: 0.5153\nEpoch 221/550\n18/18 - 0s - 6ms/step - accuracy: 0.9384 - loss: 0.2112 - val_accuracy: 0.8548 - val_loss: 0.5631\nEpoch 222/550\n18/18 - 0s - 5ms/step - accuracy: 0.9366 - loss: 0.2101 - val_accuracy: 0.8387 - val_loss: 0.5628\nEpoch 223/550\n18/18 - 0s - 5ms/step - accuracy: 0.9348 - loss: 0.2101 - val_accuracy: 0.8387 - val_loss: 0.5223\nEpoch 224/550\n18/18 - 0s - 5ms/step - accuracy: 0.9203 - loss: 0.2275 - val_accuracy: 0.8065 - val_loss: 0.5366\nEpoch 225/550\n18/18 - 0s - 5ms/step - accuracy: 0.9149 - loss: 0.2522 - val_accuracy: 0.8387 - val_loss: 0.5834\nEpoch 226/550\n18/18 - 0s - 8ms/step - accuracy: 0.9239 - loss: 0.2268 - val_accuracy: 0.8387 - val_loss: 0.4557\nEpoch 227/550\n18/18 - 0s - 8ms/step - accuracy: 0.9221 - loss: 0.2423 - val_accuracy: 0.8387 - val_loss: 0.4380\nEpoch 228/550\n18/18 - 0s - 5ms/step - accuracy: 0.9330 - loss: 0.2232 - val_accuracy: 0.8710 - val_loss: 0.4114\nEpoch 229/550\n18/18 - 0s - 8ms/step - accuracy: 0.9348 - loss: 0.2120 - val_accuracy: 0.8387 - val_loss: 0.5061\nEpoch 230/550\n18/18 - 0s - 5ms/step - accuracy: 0.9366 - loss: 0.2050 - val_accuracy: 0.8387 - val_loss: 0.4792\nEpoch 231/550\n18/18 - 0s - 6ms/step - accuracy: 0.9366 - loss: 0.2062 - val_accuracy: 0.8226 - val_loss: 0.4727\nEpoch 232/550\n18/18 - 0s - 8ms/step - accuracy: 0.9384 - loss: 0.2051 - val_accuracy: 0.8387 - val_loss: 0.5187\nEpoch 233/550\n18/18 - 0s - 8ms/step - accuracy: 0.9366 - loss: 0.2027 - val_accuracy: 0.8065 - val_loss: 0.4936\nEpoch 234/550\n18/18 - 0s - 8ms/step - accuracy: 0.9348 - loss: 0.2026 - val_accuracy: 0.8387 - val_loss: 0.4906\nEpoch 235/550\n18/18 - 0s - 8ms/step - accuracy: 0.9366 - loss: 0.2118 - val_accuracy: 0.8065 - val_loss: 0.5608\nEpoch 236/550\n18/18 - 0s - 7ms/step - accuracy: 0.9384 - loss: 0.2062 - val_accuracy: 0.8226 - val_loss: 0.5597\nEpoch 237/550\n18/18 - 0s - 6ms/step - accuracy: 0.9257 - loss: 0.2285 - val_accuracy: 0.8226 - val_loss: 0.5553\nEpoch 238/550\n18/18 - 0s - 7ms/step - accuracy: 0.9293 - loss: 0.2205 - val_accuracy: 0.8387 - val_loss: 0.6352\nEpoch 239/550\n18/18 - 0s - 8ms/step - accuracy: 0.9348 - loss: 0.2139 - val_accuracy: 0.8226 - val_loss: 0.5563\nEpoch 240/550\n18/18 - 0s - 8ms/step - accuracy: 0.9293 - loss: 0.2128 - val_accuracy: 0.8548 - val_loss: 0.5820\nEpoch 241/550\n18/18 - 0s - 8ms/step - accuracy: 0.9384 - loss: 0.2085 - val_accuracy: 0.8387 - val_loss: 0.5709\nEpoch 242/550\n18/18 - 0s - 6ms/step - accuracy: 0.9330 - loss: 0.2070 - val_accuracy: 0.8226 - val_loss: 0.5719\nEpoch 243/550\n18/18 - 0s - 6ms/step - accuracy: 0.9384 - loss: 0.2067 - val_accuracy: 0.8226 - val_loss: 0.5465\nEpoch 244/550\n18/18 - 0s - 8ms/step - accuracy: 0.9275 - loss: 0.2111 - val_accuracy: 0.8548 - val_loss: 0.5613\nEpoch 245/550\n18/18 - 0s - 5ms/step - accuracy: 0.9203 - loss: 0.2470 - val_accuracy: 0.8226 - val_loss: 0.5794\nEpoch 246/550\n18/18 - 0s - 8ms/step - accuracy: 0.9167 - loss: 0.2515 - val_accuracy: 0.8387 - val_loss: 0.4902\nEpoch 247/550\n18/18 - 0s - 9ms/step - accuracy: 0.8949 - loss: 0.3269 - val_accuracy: 0.8387 - val_loss: 0.4480\nEpoch 248/550\n18/18 - 0s - 5ms/step - accuracy: 0.8967 - loss: 0.2776 - val_accuracy: 0.8710 - val_loss: 0.3643\nEpoch 249/550\n18/18 - 0s - 5ms/step - accuracy: 0.9149 - loss: 0.2528 - val_accuracy: 0.8548 - val_loss: 0.3755\nEpoch 250/550\n18/18 - 0s - 9ms/step - accuracy: 0.9221 - loss: 0.2477 - val_accuracy: 0.8710 - val_loss: 0.3757\nEpoch 251/550\n18/18 - 0s - 7ms/step - accuracy: 0.9149 - loss: 0.2523 - val_accuracy: 0.8226 - val_loss: 0.4186\nEpoch 252/550\n18/18 - 0s - 4ms/step - accuracy: 0.9221 - loss: 0.2341 - val_accuracy: 0.8226 - val_loss: 0.4558\nEpoch 253/550\n18/18 - 0s - 8ms/step - accuracy: 0.9257 - loss: 0.2293 - val_accuracy: 0.8387 - val_loss: 0.4388\nEpoch 254/550\n18/18 - 0s - 8ms/step - accuracy: 0.9348 - loss: 0.2150 - val_accuracy: 0.8226 - val_loss: 0.4715\nEpoch 255/550\n18/18 - 0s - 5ms/step - accuracy: 0.9457 - loss: 0.2073 - val_accuracy: 0.8226 - val_loss: 0.4292\nEpoch 256/550\n18/18 - 0s - 8ms/step - accuracy: 0.9384 - loss: 0.2059 - val_accuracy: 0.8226 - val_loss: 0.4532\nEpoch 257/550\n18/18 - 0s - 5ms/step - accuracy: 0.9457 - loss: 0.2035 - val_accuracy: 0.8387 - val_loss: 0.4757\nEpoch 258/550\n18/18 - 0s - 4ms/step - accuracy: 0.9420 - loss: 0.1986 - val_accuracy: 0.8226 - val_loss: 0.4658\nEpoch 259/550\n18/18 - 0s - 8ms/step - accuracy: 0.9438 - loss: 0.1985 - val_accuracy: 0.8226 - val_loss: 0.4876\nEpoch 260/550\n18/18 - 0s - 8ms/step - accuracy: 0.9402 - loss: 0.1981 - val_accuracy: 0.8226 - val_loss: 0.4919\nEpoch 261/550\n18/18 - 0s - 4ms/step - accuracy: 0.9438 - loss: 0.1969 - val_accuracy: 0.8226 - val_loss: 0.4989\nEpoch 262/550\n18/18 - 0s - 8ms/step - accuracy: 0.9420 - loss: 0.1953 - val_accuracy: 0.8226 - val_loss: 0.4984\nEpoch 263/550\n18/18 - 0s - 8ms/step - accuracy: 0.9402 - loss: 0.1972 - val_accuracy: 0.8226 - val_loss: 0.4959\nEpoch 264/550\n18/18 - 0s - 8ms/step - accuracy: 0.9402 - loss: 0.1967 - val_accuracy: 0.8226 - val_loss: 0.5211\nEpoch 265/550\n18/18 - 0s - 8ms/step - accuracy: 0.9420 - loss: 0.1999 - val_accuracy: 0.8226 - val_loss: 0.4777\nEpoch 266/550\n18/18 - 0s - 5ms/step - accuracy: 0.9420 - loss: 0.2030 - val_accuracy: 0.8226 - val_loss: 0.5154\nEpoch 267/550\n18/18 - 0s - 5ms/step - accuracy: 0.9457 - loss: 0.1949 - val_accuracy: 0.8226 - val_loss: 0.5166\nEpoch 268/550\n18/18 - 0s - 5ms/step - accuracy: 0.9384 - loss: 0.1991 - val_accuracy: 0.8226 - val_loss: 0.5286\nEpoch 269/550\n18/18 - 0s - 7ms/step - accuracy: 0.9493 - loss: 0.1972 - val_accuracy: 0.8387 - val_loss: 0.5323\nEpoch 270/550\n18/18 - 0s - 8ms/step - accuracy: 0.9402 - loss: 0.2145 - val_accuracy: 0.8387 - val_loss: 0.5104\nEpoch 271/550\n18/18 - 0s - 5ms/step - accuracy: 0.9420 - loss: 0.2016 - val_accuracy: 0.8387 - val_loss: 0.4759\nEpoch 272/550\n18/18 - 0s - 8ms/step - accuracy: 0.9420 - loss: 0.2028 - val_accuracy: 0.8226 - val_loss: 0.5435\nEpoch 273/550\n18/18 - 0s - 5ms/step - accuracy: 0.9420 - loss: 0.1947 - val_accuracy: 0.8226 - val_loss: 0.5062\nEpoch 274/550\n18/18 - 0s - 5ms/step - accuracy: 0.9420 - loss: 0.1963 - val_accuracy: 0.8226 - val_loss: 0.5675\nEpoch 275/550\n18/18 - 0s - 5ms/step - accuracy: 0.9384 - loss: 0.1966 - val_accuracy: 0.8226 - val_loss: 0.5272\nEpoch 276/550\n18/18 - 0s - 6ms/step - accuracy: 0.9420 - loss: 0.1937 - val_accuracy: 0.8226 - val_loss: 0.5442\nEpoch 277/550\n18/18 - 0s - 7ms/step - accuracy: 0.9438 - loss: 0.1908 - val_accuracy: 0.8226 - val_loss: 0.5559\nEpoch 278/550\n18/18 - 0s - 6ms/step - accuracy: 0.9438 - loss: 0.1912 - val_accuracy: 0.8226 - val_loss: 0.5320\nEpoch 279/550\n18/18 - 0s - 6ms/step - accuracy: 0.9420 - loss: 0.1956 - val_accuracy: 0.8226 - val_loss: 0.5414\nEpoch 280/550\n18/18 - 0s - 5ms/step - accuracy: 0.9438 - loss: 0.1976 - val_accuracy: 0.8226 - val_loss: 0.5831\nEpoch 281/550\n18/18 - 0s - 7ms/step - accuracy: 0.9457 - loss: 0.1926 - val_accuracy: 0.8226 - val_loss: 0.5245\nEpoch 282/550\n18/18 - 0s - 8ms/step - accuracy: 0.9438 - loss: 0.1914 - val_accuracy: 0.8226 - val_loss: 0.5321\nEpoch 283/550\n18/18 - 0s - 5ms/step - accuracy: 0.9475 - loss: 0.1903 - val_accuracy: 0.8226 - val_loss: 0.5535\nEpoch 284/550\n18/18 - 0s - 8ms/step - accuracy: 0.9438 - loss: 0.1893 - val_accuracy: 0.8226 - val_loss: 0.5364\nEpoch 285/550\n18/18 - 0s - 5ms/step - accuracy: 0.9475 - loss: 0.1917 - val_accuracy: 0.8226 - val_loss: 0.5444\nEpoch 286/550\n18/18 - 0s - 5ms/step - accuracy: 0.9457 - loss: 0.1892 - val_accuracy: 0.8226 - val_loss: 0.5399\nEpoch 287/550\n18/18 - 0s - 8ms/step - accuracy: 0.9457 - loss: 0.1913 - val_accuracy: 0.8226 - val_loss: 0.5574\nEpoch 288/550\n18/18 - 0s - 8ms/step - accuracy: 0.9384 - loss: 0.1971 - val_accuracy: 0.8226 - val_loss: 0.5517\nEpoch 289/550\n18/18 - 0s - 7ms/step - accuracy: 0.9438 - loss: 0.1986 - val_accuracy: 0.8226 - val_loss: 0.5438\nEpoch 290/550\n18/18 - 0s - 5ms/step - accuracy: 0.9475 - loss: 0.1949 - val_accuracy: 0.8226 - val_loss: 0.5148\nEpoch 291/550\n18/18 - 0s - 8ms/step - accuracy: 0.9457 - loss: 0.1915 - val_accuracy: 0.8226 - val_loss: 0.5374\nEpoch 292/550\n18/18 - 0s - 7ms/step - accuracy: 0.9293 - loss: 0.2291 - val_accuracy: 0.7903 - val_loss: 0.6535\nEpoch 293/550\n18/18 - 0s - 5ms/step - accuracy: 0.9275 - loss: 0.2297 - val_accuracy: 0.8387 - val_loss: 0.6096\nEpoch 294/550\n18/18 - 0s - 5ms/step - accuracy: 0.9149 - loss: 0.2508 - val_accuracy: 0.8387 - val_loss: 0.4666\nEpoch 295/550\n18/18 - 0s - 4ms/step - accuracy: 0.9275 - loss: 0.2355 - val_accuracy: 0.8226 - val_loss: 0.5735\nEpoch 296/550\n18/18 - 0s - 8ms/step - accuracy: 0.9384 - loss: 0.2036 - val_accuracy: 0.8226 - val_loss: 0.5392\nEpoch 297/550\n18/18 - 0s - 5ms/step - accuracy: 0.9384 - loss: 0.2067 - val_accuracy: 0.8226 - val_loss: 0.5772\nEpoch 298/550\n18/18 - 0s - 8ms/step - accuracy: 0.9384 - loss: 0.2003 - val_accuracy: 0.8226 - val_loss: 0.5747\nEpoch 299/550\n18/18 - 0s - 8ms/step - accuracy: 0.9384 - loss: 0.2112 - val_accuracy: 0.8226 - val_loss: 0.5424\nEpoch 300/550\n18/18 - 0s - 8ms/step - accuracy: 0.9384 - loss: 0.2049 - val_accuracy: 0.8226 - val_loss: 0.6434\nEpoch 301/550\n18/18 - 0s - 5ms/step - accuracy: 0.9366 - loss: 0.2009 - val_accuracy: 0.8226 - val_loss: 0.5058\nEpoch 302/550\n18/18 - 0s - 8ms/step - accuracy: 0.9366 - loss: 0.2037 - val_accuracy: 0.8226 - val_loss: 0.6515\nEpoch 303/550\n18/18 - 0s - 5ms/step - accuracy: 0.9420 - loss: 0.2021 - val_accuracy: 0.8065 - val_loss: 0.5561\nEpoch 304/550\n18/18 - 0s - 8ms/step - accuracy: 0.9185 - loss: 0.2388 - val_accuracy: 0.8387 - val_loss: 0.5055\nEpoch 305/550\n18/18 - 0s - 7ms/step - accuracy: 0.9221 - loss: 0.2531 - val_accuracy: 0.8387 - val_loss: 0.4632\nEpoch 306/550\n18/18 - 0s - 5ms/step - accuracy: 0.9257 - loss: 0.2181 - val_accuracy: 0.8387 - val_loss: 0.4605\nEpoch 307/550\n18/18 - 0s - 5ms/step - accuracy: 0.9330 - loss: 0.2172 - val_accuracy: 0.8226 - val_loss: 0.5386\nEpoch 308/550\n18/18 - 0s - 5ms/step - accuracy: 0.9330 - loss: 0.2174 - val_accuracy: 0.8387 - val_loss: 0.5697\nEpoch 309/550\n18/18 - 0s - 7ms/step - accuracy: 0.9384 - loss: 0.2087 - val_accuracy: 0.8065 - val_loss: 0.5210\nEpoch 310/550\n18/18 - 0s - 9ms/step - accuracy: 0.9384 - loss: 0.2019 - val_accuracy: 0.7903 - val_loss: 0.5576\nEpoch 311/550\n18/18 - 0s - 6ms/step - accuracy: 0.9420 - loss: 0.1947 - val_accuracy: 0.8226 - val_loss: 0.5245\nEpoch 312/550\n18/18 - 0s - 7ms/step - accuracy: 0.9475 - loss: 0.1880 - val_accuracy: 0.8226 - val_loss: 0.5285\nEpoch 313/550\n18/18 - 0s - 8ms/step - accuracy: 0.9493 - loss: 0.1865 - val_accuracy: 0.8226 - val_loss: 0.5526\nEpoch 314/550\n18/18 - 0s - 7ms/step - accuracy: 0.9438 - loss: 0.1893 - val_accuracy: 0.8065 - val_loss: 0.5525\nEpoch 315/550\n18/18 - 0s - 5ms/step - accuracy: 0.9493 - loss: 0.1891 - val_accuracy: 0.8226 - val_loss: 0.5508\nEpoch 316/550\n18/18 - 0s - 8ms/step - accuracy: 0.9475 - loss: 0.1962 - val_accuracy: 0.8226 - val_loss: 0.5389\nEpoch 317/550\n18/18 - 0s - 5ms/step - accuracy: 0.9457 - loss: 0.1911 - val_accuracy: 0.8226 - val_loss: 0.5800\nEpoch 318/550\n18/18 - 0s - 8ms/step - accuracy: 0.9420 - loss: 0.1933 - val_accuracy: 0.8226 - val_loss: 0.5533\nEpoch 319/550\n18/18 - 0s - 5ms/step - accuracy: 0.9457 - loss: 0.1870 - val_accuracy: 0.8226 - val_loss: 0.5608\nEpoch 320/550\n18/18 - 0s - 5ms/step - accuracy: 0.9475 - loss: 0.1842 - val_accuracy: 0.8226 - val_loss: 0.5688\nEpoch 321/550\n18/18 - 0s - 8ms/step - accuracy: 0.9438 - loss: 0.1877 - val_accuracy: 0.8226 - val_loss: 0.5118\nEpoch 322/550\n18/18 - 0s - 7ms/step - accuracy: 0.9475 - loss: 0.1890 - val_accuracy: 0.8226 - val_loss: 0.5857\nEpoch 323/550\n18/18 - 0s - 7ms/step - accuracy: 0.9438 - loss: 0.1886 - val_accuracy: 0.8226 - val_loss: 0.5544\nEpoch 324/550\n18/18 - 0s - 8ms/step - accuracy: 0.9402 - loss: 0.2066 - val_accuracy: 0.8226 - val_loss: 0.5391\nEpoch 325/550\n18/18 - 0s - 5ms/step - accuracy: 0.9457 - loss: 0.1942 - val_accuracy: 0.8387 - val_loss: 0.4936\nEpoch 326/550\n18/18 - 0s - 8ms/step - accuracy: 0.9384 - loss: 0.2039 - val_accuracy: 0.8226 - val_loss: 0.4885\nEpoch 327/550\n18/18 - 0s - 7ms/step - accuracy: 0.9420 - loss: 0.1975 - val_accuracy: 0.8387 - val_loss: 0.5166\nEpoch 328/550\n18/18 - 0s - 6ms/step - accuracy: 0.9402 - loss: 0.2090 - val_accuracy: 0.8548 - val_loss: 0.5459\nEpoch 329/550\n18/18 - 0s - 7ms/step - accuracy: 0.9366 - loss: 0.2169 - val_accuracy: 0.8548 - val_loss: 0.4641\nEpoch 330/550\n18/18 - 0s - 5ms/step - accuracy: 0.9420 - loss: 0.1965 - val_accuracy: 0.8065 - val_loss: 0.5481\nEpoch 331/550\n18/18 - 0s - 8ms/step - accuracy: 0.9438 - loss: 0.1959 - val_accuracy: 0.8226 - val_loss: 0.4484\nEpoch 332/550\n18/18 - 0s - 6ms/step - accuracy: 0.9438 - loss: 0.1917 - val_accuracy: 0.8065 - val_loss: 0.5139\nEpoch 333/550\n18/18 - 0s - 7ms/step - accuracy: 0.9438 - loss: 0.1895 - val_accuracy: 0.8226 - val_loss: 0.4720\nEpoch 334/550\n18/18 - 0s - 8ms/step - accuracy: 0.9438 - loss: 0.1902 - val_accuracy: 0.8226 - val_loss: 0.5574\nEpoch 335/550\n18/18 - 0s - 5ms/step - accuracy: 0.9493 - loss: 0.1850 - val_accuracy: 0.8226 - val_loss: 0.5550\nEpoch 336/550\n18/18 - 0s - 7ms/step - accuracy: 0.9457 - loss: 0.1831 - val_accuracy: 0.8226 - val_loss: 0.5294\nEpoch 337/550\n18/18 - 0s - 7ms/step - accuracy: 0.9457 - loss: 0.1826 - val_accuracy: 0.8226 - val_loss: 0.5145\nEpoch 338/550\n18/18 - 0s - 6ms/step - accuracy: 0.9493 - loss: 0.1819 - val_accuracy: 0.8226 - val_loss: 0.5125\nEpoch 339/550\n18/18 - 0s - 7ms/step - accuracy: 0.9475 - loss: 0.1829 - val_accuracy: 0.8226 - val_loss: 0.4858\nEpoch 340/550\n18/18 - 0s - 8ms/step - accuracy: 0.9493 - loss: 0.1820 - val_accuracy: 0.8226 - val_loss: 0.5489\nEpoch 341/550\n18/18 - 0s - 5ms/step - accuracy: 0.9475 - loss: 0.1844 - val_accuracy: 0.8226 - val_loss: 0.5475\nEpoch 342/550\n18/18 - 0s - 6ms/step - accuracy: 0.9420 - loss: 0.1962 - val_accuracy: 0.8226 - val_loss: 0.4984\nEpoch 343/550\n18/18 - 0s - 4ms/step - accuracy: 0.9438 - loss: 0.1924 - val_accuracy: 0.8226 - val_loss: 0.5479\nEpoch 344/550\n18/18 - 0s - 5ms/step - accuracy: 0.9312 - loss: 0.2154 - val_accuracy: 0.8065 - val_loss: 0.6176\nEpoch 345/550\n18/18 - 0s - 5ms/step - accuracy: 0.9420 - loss: 0.2076 - val_accuracy: 0.8226 - val_loss: 0.5889\nEpoch 346/550\n18/18 - 0s - 8ms/step - accuracy: 0.9402 - loss: 0.2029 - val_accuracy: 0.8065 - val_loss: 0.6035\nEpoch 347/550\n18/18 - 0s - 5ms/step - accuracy: 0.9312 - loss: 0.2165 - val_accuracy: 0.8065 - val_loss: 0.6998\nEpoch 348/550\n18/18 - 0s - 5ms/step - accuracy: 0.9257 - loss: 0.2200 - val_accuracy: 0.8548 - val_loss: 0.4882\nEpoch 349/550\n18/18 - 0s - 5ms/step - accuracy: 0.9420 - loss: 0.2037 - val_accuracy: 0.8548 - val_loss: 0.4594\nEpoch 350/550\n18/18 - 0s - 7ms/step - accuracy: 0.9438 - loss: 0.2041 - val_accuracy: 0.8387 - val_loss: 0.4842\nEpoch 351/550\n18/18 - 0s - 7ms/step - accuracy: 0.9438 - loss: 0.1948 - val_accuracy: 0.8226 - val_loss: 0.4887\nEpoch 352/550\n18/18 - 0s - 5ms/step - accuracy: 0.9420 - loss: 0.1979 - val_accuracy: 0.8226 - val_loss: 0.6000\nEpoch 353/550\n18/18 - 0s - 5ms/step - accuracy: 0.9348 - loss: 0.2082 - val_accuracy: 0.8226 - val_loss: 0.5566\nEpoch 354/550\n18/18 - 0s - 6ms/step - accuracy: 0.9366 - loss: 0.2164 - val_accuracy: 0.8387 - val_loss: 0.4884\nEpoch 355/550\n18/18 - 0s - 5ms/step - accuracy: 0.9366 - loss: 0.2005 - val_accuracy: 0.8226 - val_loss: 0.6980\nEpoch 356/550\n18/18 - 0s - 8ms/step - accuracy: 0.9438 - loss: 0.2142 - val_accuracy: 0.8548 - val_loss: 0.4688\nEpoch 357/550\n18/18 - 0s - 8ms/step - accuracy: 0.9366 - loss: 0.2008 - val_accuracy: 0.8387 - val_loss: 0.5097\nEpoch 358/550\n18/18 - 0s - 8ms/step - accuracy: 0.9366 - loss: 0.2093 - val_accuracy: 0.8226 - val_loss: 0.6637\nEpoch 359/550\n18/18 - 0s - 8ms/step - accuracy: 0.9366 - loss: 0.2005 - val_accuracy: 0.8226 - val_loss: 0.6291\nEpoch 360/550\n18/18 - 0s - 5ms/step - accuracy: 0.9457 - loss: 0.1923 - val_accuracy: 0.8065 - val_loss: 0.6112\nEpoch 361/550\n18/18 - 0s - 8ms/step - accuracy: 0.9420 - loss: 0.1848 - val_accuracy: 0.8065 - val_loss: 0.5859\nEpoch 362/550\n18/18 - 0s - 5ms/step - accuracy: 0.9493 - loss: 0.1845 - val_accuracy: 0.8065 - val_loss: 0.5972\nEpoch 363/550\n18/18 - 0s - 7ms/step - accuracy: 0.9511 - loss: 0.1839 - val_accuracy: 0.8065 - val_loss: 0.5701\nEpoch 364/550\n18/18 - 0s - 5ms/step - accuracy: 0.9475 - loss: 0.1822 - val_accuracy: 0.8226 - val_loss: 0.5864\nEpoch 365/550\n18/18 - 0s - 8ms/step - accuracy: 0.9475 - loss: 0.1936 - val_accuracy: 0.8226 - val_loss: 0.5403\nEpoch 366/550\n18/18 - 0s - 5ms/step - accuracy: 0.9457 - loss: 0.1888 - val_accuracy: 0.8226 - val_loss: 0.6000\nEpoch 367/550\n18/18 - 0s - 8ms/step - accuracy: 0.9493 - loss: 0.1849 - val_accuracy: 0.8226 - val_loss: 0.5384\nEpoch 368/550\n18/18 - 0s - 5ms/step - accuracy: 0.9457 - loss: 0.1901 - val_accuracy: 0.8226 - val_loss: 0.6337\nEpoch 369/550\n18/18 - 0s - 8ms/step - accuracy: 0.9457 - loss: 0.1857 - val_accuracy: 0.8226 - val_loss: 0.5723\nEpoch 370/550\n18/18 - 0s - 6ms/step - accuracy: 0.9511 - loss: 0.1854 - val_accuracy: 0.8065 - val_loss: 0.5511\nEpoch 371/550\n18/18 - 0s - 5ms/step - accuracy: 0.9493 - loss: 0.1808 - val_accuracy: 0.8226 - val_loss: 0.6112\nEpoch 372/550\n18/18 - 0s - 8ms/step - accuracy: 0.9457 - loss: 0.1837 - val_accuracy: 0.8226 - val_loss: 0.5633\nEpoch 373/550\n18/18 - 0s - 5ms/step - accuracy: 0.9475 - loss: 0.1831 - val_accuracy: 0.8226 - val_loss: 0.6184\nEpoch 374/550\n18/18 - 0s - 8ms/step - accuracy: 0.9511 - loss: 0.1805 - val_accuracy: 0.8226 - val_loss: 0.5722\nEpoch 375/550\n18/18 - 0s - 5ms/step - accuracy: 0.9475 - loss: 0.1814 - val_accuracy: 0.8226 - val_loss: 0.6058\nEpoch 376/550\n18/18 - 0s - 8ms/step - accuracy: 0.9493 - loss: 0.1850 - val_accuracy: 0.8387 - val_loss: 0.6534\nEpoch 377/550\n18/18 - 0s - 5ms/step - accuracy: 0.9475 - loss: 0.1871 - val_accuracy: 0.8065 - val_loss: 0.6274\nEpoch 378/550\n18/18 - 0s - 8ms/step - accuracy: 0.9493 - loss: 0.1810 - val_accuracy: 0.8065 - val_loss: 0.6661\nEpoch 379/550\n18/18 - 0s - 8ms/step - accuracy: 0.9493 - loss: 0.1808 - val_accuracy: 0.8226 - val_loss: 0.7199\nEpoch 380/550\n18/18 - 0s - 8ms/step - accuracy: 0.9475 - loss: 0.1833 - val_accuracy: 0.8065 - val_loss: 0.5606\nEpoch 381/550\n18/18 - 0s - 9ms/step - accuracy: 0.9457 - loss: 0.1938 - val_accuracy: 0.8226 - val_loss: 0.7061\nEpoch 382/550\n18/18 - 0s - 7ms/step - accuracy: 0.9475 - loss: 0.1876 - val_accuracy: 0.8226 - val_loss: 0.5574\nEpoch 383/550\n18/18 - 0s - 8ms/step - accuracy: 0.9457 - loss: 0.1809 - val_accuracy: 0.8065 - val_loss: 0.6075\nEpoch 384/550\n18/18 - 0s - 6ms/step - accuracy: 0.9511 - loss: 0.1798 - val_accuracy: 0.8065 - val_loss: 0.6140\nEpoch 385/550\n18/18 - 0s - 7ms/step - accuracy: 0.9493 - loss: 0.1833 - val_accuracy: 0.8065 - val_loss: 0.5762\nEpoch 386/550\n18/18 - 0s - 5ms/step - accuracy: 0.9493 - loss: 0.1792 - val_accuracy: 0.8226 - val_loss: 0.6067\nEpoch 387/550\n18/18 - 0s - 5ms/step - accuracy: 0.9493 - loss: 0.1791 - val_accuracy: 0.8065 - val_loss: 0.5678\nEpoch 388/550\n18/18 - 0s - 5ms/step - accuracy: 0.9457 - loss: 0.1855 - val_accuracy: 0.8226 - val_loss: 0.6159\nEpoch 389/550\n18/18 - 0s - 5ms/step - accuracy: 0.9511 - loss: 0.1787 - val_accuracy: 0.8065 - val_loss: 0.5412\nEpoch 390/550\n18/18 - 0s - 6ms/step - accuracy: 0.9438 - loss: 0.1847 - val_accuracy: 0.8387 - val_loss: 0.6222\nEpoch 391/550\n18/18 - 0s - 7ms/step - accuracy: 0.9493 - loss: 0.1868 - val_accuracy: 0.8226 - val_loss: 0.5644\nEpoch 392/550\n18/18 - 0s - 7ms/step - accuracy: 0.9420 - loss: 0.1893 - val_accuracy: 0.8065 - val_loss: 0.6032\nEpoch 393/550\n18/18 - 0s - 5ms/step - accuracy: 0.9457 - loss: 0.1896 - val_accuracy: 0.8065 - val_loss: 0.5966\nEpoch 394/550\n18/18 - 0s - 8ms/step - accuracy: 0.9348 - loss: 0.2075 - val_accuracy: 0.8226 - val_loss: 0.6131\nEpoch 395/550\n18/18 - 0s - 6ms/step - accuracy: 0.9402 - loss: 0.2026 - val_accuracy: 0.8065 - val_loss: 0.6844\nEpoch 396/550\n18/18 - 0s - 5ms/step - accuracy: 0.9312 - loss: 0.2347 - val_accuracy: 0.8226 - val_loss: 0.5728\nEpoch 397/550\n18/18 - 0s - 6ms/step - accuracy: 0.9275 - loss: 0.2308 - val_accuracy: 0.8387 - val_loss: 0.5355\nEpoch 398/550\n18/18 - 0s - 5ms/step - accuracy: 0.9330 - loss: 0.2129 - val_accuracy: 0.8226 - val_loss: 0.6711\nEpoch 399/550\n18/18 - 0s - 7ms/step - accuracy: 0.9366 - loss: 0.2018 - val_accuracy: 0.8226 - val_loss: 0.5878\nEpoch 400/550\n18/18 - 0s - 9ms/step - accuracy: 0.9366 - loss: 0.2083 - val_accuracy: 0.8387 - val_loss: 0.5671\nEpoch 401/550\n18/18 - 0s - 7ms/step - accuracy: 0.9167 - loss: 0.2492 - val_accuracy: 0.8387 - val_loss: 0.5175\nEpoch 402/550\n18/18 - 0s - 6ms/step - accuracy: 0.9239 - loss: 0.2478 - val_accuracy: 0.7903 - val_loss: 0.7794\nEpoch 403/550\n18/18 - 0s - 5ms/step - accuracy: 0.9330 - loss: 0.2193 - val_accuracy: 0.8387 - val_loss: 0.5674\nEpoch 404/550\n18/18 - 0s - 8ms/step - accuracy: 0.9366 - loss: 0.2093 - val_accuracy: 0.8387 - val_loss: 0.6304\nEpoch 405/550\n18/18 - 0s - 8ms/step - accuracy: 0.9366 - loss: 0.2067 - val_accuracy: 0.8548 - val_loss: 0.5205\nEpoch 406/550\n18/18 - 0s - 5ms/step - accuracy: 0.9438 - loss: 0.1962 - val_accuracy: 0.8387 - val_loss: 0.5991\nEpoch 407/550\n18/18 - 0s - 7ms/step - accuracy: 0.9457 - loss: 0.1870 - val_accuracy: 0.8226 - val_loss: 0.5677\nEpoch 408/550\n18/18 - 0s - 9ms/step - accuracy: 0.9475 - loss: 0.1873 - val_accuracy: 0.8226 - val_loss: 0.5970\nEpoch 409/550\n18/18 - 0s - 6ms/step - accuracy: 0.9475 - loss: 0.1843 - val_accuracy: 0.8387 - val_loss: 0.5936\nEpoch 410/550\n18/18 - 0s - 8ms/step - accuracy: 0.9493 - loss: 0.1835 - val_accuracy: 0.8387 - val_loss: 0.6161\nEpoch 411/550\n18/18 - 0s - 8ms/step - accuracy: 0.9457 - loss: 0.1843 - val_accuracy: 0.8387 - val_loss: 0.6649\nEpoch 412/550\n18/18 - 0s - 8ms/step - accuracy: 0.9457 - loss: 0.1872 - val_accuracy: 0.8387 - val_loss: 0.5321\nEpoch 413/550\n18/18 - 0s - 5ms/step - accuracy: 0.9457 - loss: 0.1932 - val_accuracy: 0.8226 - val_loss: 0.5980\nEpoch 414/550\n18/18 - 0s - 8ms/step - accuracy: 0.9457 - loss: 0.1846 - val_accuracy: 0.8387 - val_loss: 0.5708\nEpoch 415/550\n18/18 - 0s - 9ms/step - accuracy: 0.9457 - loss: 0.1841 - val_accuracy: 0.8387 - val_loss: 0.5769\nEpoch 416/550\n18/18 - 0s - 5ms/step - accuracy: 0.9475 - loss: 0.1827 - val_accuracy: 0.8226 - val_loss: 0.6266\nEpoch 417/550\n18/18 - 0s - 7ms/step - accuracy: 0.9475 - loss: 0.1840 - val_accuracy: 0.8387 - val_loss: 0.6058\nEpoch 418/550\n18/18 - 0s - 8ms/step - accuracy: 0.9438 - loss: 0.1920 - val_accuracy: 0.8387 - val_loss: 0.6469\nEpoch 419/550\n18/18 - 0s - 8ms/step - accuracy: 0.9475 - loss: 0.1807 - val_accuracy: 0.8387 - val_loss: 0.6143\nEpoch 420/550\n18/18 - 0s - 8ms/step - accuracy: 0.9457 - loss: 0.1842 - val_accuracy: 0.8387 - val_loss: 0.6441\nEpoch 421/550\n18/18 - 0s - 8ms/step - accuracy: 0.9457 - loss: 0.1857 - val_accuracy: 0.8387 - val_loss: 0.6840\nEpoch 422/550\n18/18 - 0s - 7ms/step - accuracy: 0.9438 - loss: 0.1899 - val_accuracy: 0.8387 - val_loss: 0.5552\nEpoch 423/550\n18/18 - 0s - 8ms/step - accuracy: 0.9493 - loss: 0.1841 - val_accuracy: 0.8387 - val_loss: 0.6539\nEpoch 424/550\n18/18 - 0s - 7ms/step - accuracy: 0.9438 - loss: 0.1894 - val_accuracy: 0.8226 - val_loss: 0.6730\nEpoch 425/550\n18/18 - 0s - 8ms/step - accuracy: 0.9511 - loss: 0.1821 - val_accuracy: 0.8387 - val_loss: 0.6841\nEpoch 426/550\n18/18 - 0s - 8ms/step - accuracy: 0.9511 - loss: 0.1874 - val_accuracy: 0.8387 - val_loss: 0.5919\nEpoch 427/550\n18/18 - 0s - 8ms/step - accuracy: 0.9475 - loss: 0.1834 - val_accuracy: 0.8387 - val_loss: 0.6561\nEpoch 428/550\n18/18 - 0s - 8ms/step - accuracy: 0.9475 - loss: 0.1837 - val_accuracy: 0.8387 - val_loss: 0.6638\nEpoch 429/550\n18/18 - 0s - 5ms/step - accuracy: 0.9475 - loss: 0.1829 - val_accuracy: 0.8387 - val_loss: 0.6854\nEpoch 430/550\n18/18 - 0s - 4ms/step - accuracy: 0.9475 - loss: 0.1832 - val_accuracy: 0.8226 - val_loss: 0.6210\nEpoch 431/550\n18/18 - 0s - 8ms/step - accuracy: 0.9475 - loss: 0.1847 - val_accuracy: 0.8387 - val_loss: 0.6735\nEpoch 432/550\n18/18 - 0s - 4ms/step - accuracy: 0.9493 - loss: 0.1829 - val_accuracy: 0.8387 - val_loss: 0.6751\nEpoch 433/550\n18/18 - 0s - 8ms/step - accuracy: 0.9475 - loss: 0.1821 - val_accuracy: 0.8387 - val_loss: 0.6616\nEpoch 434/550\n18/18 - 0s - 8ms/step - accuracy: 0.9493 - loss: 0.1823 - val_accuracy: 0.8226 - val_loss: 0.6382\nEpoch 435/550\n18/18 - 0s - 4ms/step - accuracy: 0.9511 - loss: 0.1861 - val_accuracy: 0.8387 - val_loss: 0.7382\nEpoch 436/550\n18/18 - 0s - 4ms/step - accuracy: 0.9457 - loss: 0.1856 - val_accuracy: 0.8387 - val_loss: 0.6385\nEpoch 437/550\n18/18 - 0s - 8ms/step - accuracy: 0.9438 - loss: 0.1932 - val_accuracy: 0.8387 - val_loss: 0.6789\nEpoch 438/550\n18/18 - 0s - 8ms/step - accuracy: 0.9402 - loss: 0.1862 - val_accuracy: 0.8387 - val_loss: 0.7752\nEpoch 439/550\n18/18 - 0s - 4ms/step - accuracy: 0.9475 - loss: 0.1927 - val_accuracy: 0.8387 - val_loss: 0.6123\nEpoch 440/550\n18/18 - 0s - 8ms/step - accuracy: 0.9402 - loss: 0.1983 - val_accuracy: 0.8548 - val_loss: 0.5023\nEpoch 441/550\n18/18 - 0s - 8ms/step - accuracy: 0.9438 - loss: 0.1888 - val_accuracy: 0.8065 - val_loss: 0.6195\nEpoch 442/550\n18/18 - 0s - 8ms/step - accuracy: 0.9457 - loss: 0.1877 - val_accuracy: 0.8548 - val_loss: 0.4813\nEpoch 443/550\n18/18 - 0s - 9ms/step - accuracy: 0.9420 - loss: 0.1899 - val_accuracy: 0.8387 - val_loss: 0.6124\nEpoch 444/550\n18/18 - 0s - 8ms/step - accuracy: 0.9366 - loss: 0.2116 - val_accuracy: 0.8065 - val_loss: 0.7101\nEpoch 445/550\n18/18 - 0s - 5ms/step - accuracy: 0.9312 - loss: 0.2220 - val_accuracy: 0.8065 - val_loss: 0.5775\nEpoch 446/550\n18/18 - 0s - 7ms/step - accuracy: 0.9203 - loss: 0.2310 - val_accuracy: 0.8710 - val_loss: 0.5251\nEpoch 447/550\n18/18 - 0s - 8ms/step - accuracy: 0.9366 - loss: 0.2122 - val_accuracy: 0.8226 - val_loss: 0.6772\nEpoch 448/550\n18/18 - 0s - 8ms/step - accuracy: 0.9330 - loss: 0.2025 - val_accuracy: 0.8387 - val_loss: 0.5640\nEpoch 449/550\n18/18 - 0s - 8ms/step - accuracy: 0.9420 - loss: 0.1960 - val_accuracy: 0.8387 - val_loss: 0.6971\nEpoch 450/550\n18/18 - 0s - 8ms/step - accuracy: 0.9402 - loss: 0.2012 - val_accuracy: 0.8387 - val_loss: 0.7182\nEpoch 451/550\n18/18 - 0s - 8ms/step - accuracy: 0.9457 - loss: 0.1915 - val_accuracy: 0.8226 - val_loss: 0.6692\nEpoch 452/550\n18/18 - 0s - 5ms/step - accuracy: 0.9420 - loss: 0.1920 - val_accuracy: 0.8387 - val_loss: 0.5255\nEpoch 453/550\n18/18 - 0s - 8ms/step - accuracy: 0.9384 - loss: 0.2146 - val_accuracy: 0.8226 - val_loss: 0.5226\nEpoch 454/550\n18/18 - 0s - 6ms/step - accuracy: 0.9348 - loss: 0.2042 - val_accuracy: 0.8226 - val_loss: 0.7341\nEpoch 455/550\n18/18 - 0s - 8ms/step - accuracy: 0.9384 - loss: 0.1928 - val_accuracy: 0.8065 - val_loss: 0.6368\nEpoch 456/550\n18/18 - 0s - 9ms/step - accuracy: 0.9493 - loss: 0.1851 - val_accuracy: 0.8387 - val_loss: 0.6538\nEpoch 457/550\n18/18 - 0s - 7ms/step - accuracy: 0.9420 - loss: 0.2044 - val_accuracy: 0.8226 - val_loss: 0.6462\nEpoch 458/550\n18/18 - 0s - 5ms/step - accuracy: 0.9312 - loss: 0.2216 - val_accuracy: 0.8710 - val_loss: 0.5549\nEpoch 459/550\n18/18 - 0s - 6ms/step - accuracy: 0.9348 - loss: 0.2145 - val_accuracy: 0.8548 - val_loss: 0.5748\nEpoch 460/550\n18/18 - 0s - 8ms/step - accuracy: 0.9312 - loss: 0.2218 - val_accuracy: 0.8226 - val_loss: 0.7536\nEpoch 461/550\n18/18 - 0s - 8ms/step - accuracy: 0.9293 - loss: 0.2346 - val_accuracy: 0.8387 - val_loss: 0.5603\nEpoch 462/550\n18/18 - 0s - 8ms/step - accuracy: 0.9221 - loss: 0.2404 - val_accuracy: 0.8710 - val_loss: 0.4585\nEpoch 463/550\n18/18 - 0s - 8ms/step - accuracy: 0.9366 - loss: 0.2145 - val_accuracy: 0.8710 - val_loss: 0.4588\nEpoch 464/550\n18/18 - 0s - 7ms/step - accuracy: 0.9366 - loss: 0.2189 - val_accuracy: 0.8387 - val_loss: 0.6777\nEpoch 465/550\n18/18 - 0s - 5ms/step - accuracy: 0.9293 - loss: 0.2342 - val_accuracy: 0.8710 - val_loss: 0.4596\nEpoch 466/550\n18/18 - 0s - 8ms/step - accuracy: 0.9221 - loss: 0.2434 - val_accuracy: 0.8387 - val_loss: 0.4753\nEpoch 467/550\n18/18 - 0s - 5ms/step - accuracy: 0.9275 - loss: 0.2358 - val_accuracy: 0.8871 - val_loss: 0.4393\nEpoch 468/550\n18/18 - 0s - 8ms/step - accuracy: 0.9348 - loss: 0.2145 - val_accuracy: 0.8548 - val_loss: 0.4526\nEpoch 469/550\n18/18 - 0s - 5ms/step - accuracy: 0.9402 - loss: 0.2068 - val_accuracy: 0.8548 - val_loss: 0.4679\nEpoch 470/550\n18/18 - 0s - 8ms/step - accuracy: 0.9366 - loss: 0.2082 - val_accuracy: 0.8710 - val_loss: 0.4579\nEpoch 471/550\n18/18 - 0s - 5ms/step - accuracy: 0.9420 - loss: 0.2030 - val_accuracy: 0.8548 - val_loss: 0.4805\nEpoch 472/550\n18/18 - 0s - 5ms/step - accuracy: 0.9366 - loss: 0.2068 - val_accuracy: 0.8387 - val_loss: 0.4849\nEpoch 473/550\n18/18 - 0s - 7ms/step - accuracy: 0.9420 - loss: 0.2010 - val_accuracy: 0.8387 - val_loss: 0.6359\nEpoch 474/550\n18/18 - 0s - 8ms/step - accuracy: 0.9384 - loss: 0.2021 - val_accuracy: 0.8387 - val_loss: 0.5838\nEpoch 475/550\n18/18 - 0s - 8ms/step - accuracy: 0.9438 - loss: 0.1987 - val_accuracy: 0.8387 - val_loss: 0.5866\nEpoch 476/550\n18/18 - 0s - 5ms/step - accuracy: 0.9420 - loss: 0.1976 - val_accuracy: 0.8387 - val_loss: 0.5762\nEpoch 477/550\n18/18 - 0s - 6ms/step - accuracy: 0.9420 - loss: 0.1951 - val_accuracy: 0.8387 - val_loss: 0.5789\nEpoch 478/550\n18/18 - 0s - 6ms/step - accuracy: 0.9438 - loss: 0.1940 - val_accuracy: 0.8387 - val_loss: 0.6064\nEpoch 479/550\n18/18 - 0s - 5ms/step - accuracy: 0.9402 - loss: 0.1988 - val_accuracy: 0.8387 - val_loss: 0.5652\nEpoch 480/550\n18/18 - 0s - 7ms/step - accuracy: 0.9420 - loss: 0.1972 - val_accuracy: 0.8387 - val_loss: 0.5627\nEpoch 481/550\n18/18 - 0s - 8ms/step - accuracy: 0.9402 - loss: 0.1994 - val_accuracy: 0.8387 - val_loss: 0.6209\nEpoch 482/550\n18/18 - 0s - 4ms/step - accuracy: 0.9438 - loss: 0.1977 - val_accuracy: 0.8226 - val_loss: 0.5496\nEpoch 483/550\n18/18 - 0s - 8ms/step - accuracy: 0.9438 - loss: 0.1997 - val_accuracy: 0.8387 - val_loss: 0.6151\nEpoch 484/550\n18/18 - 0s - 8ms/step - accuracy: 0.9438 - loss: 0.1948 - val_accuracy: 0.8387 - val_loss: 0.5625\nEpoch 485/550\n18/18 - 0s - 8ms/step - accuracy: 0.9384 - loss: 0.1967 - val_accuracy: 0.8387 - val_loss: 0.5873\nEpoch 486/550\n18/18 - 0s - 8ms/step - accuracy: 0.9420 - loss: 0.1949 - val_accuracy: 0.8387 - val_loss: 0.6090\nEpoch 487/550\n18/18 - 0s - 5ms/step - accuracy: 0.9366 - loss: 0.2036 - val_accuracy: 0.8387 - val_loss: 0.5541\nEpoch 488/550\n18/18 - 0s - 5ms/step - accuracy: 0.9420 - loss: 0.1945 - val_accuracy: 0.8387 - val_loss: 0.5763\nEpoch 489/550\n18/18 - 0s - 8ms/step - accuracy: 0.9420 - loss: 0.1938 - val_accuracy: 0.8387 - val_loss: 0.5834\nEpoch 490/550\n18/18 - 0s - 8ms/step - accuracy: 0.9475 - loss: 0.1936 - val_accuracy: 0.8387 - val_loss: 0.6096\nEpoch 491/550\n18/18 - 0s - 4ms/step - accuracy: 0.9457 - loss: 0.1939 - val_accuracy: 0.8387 - val_loss: 0.6317\nEpoch 492/550\n18/18 - 0s - 5ms/step - accuracy: 0.9402 - loss: 0.1940 - val_accuracy: 0.8387 - val_loss: 0.5932\nEpoch 493/550\n18/18 - 0s - 8ms/step - accuracy: 0.9420 - loss: 0.1944 - val_accuracy: 0.8387 - val_loss: 0.6458\nEpoch 494/550\n18/18 - 0s - 5ms/step - accuracy: 0.9438 - loss: 0.1940 - val_accuracy: 0.8387 - val_loss: 0.5864\nEpoch 495/550\n18/18 - 0s - 8ms/step - accuracy: 0.9402 - loss: 0.1953 - val_accuracy: 0.8387 - val_loss: 0.6010\nEpoch 496/550\n18/18 - 0s - 7ms/step - accuracy: 0.9438 - loss: 0.1948 - val_accuracy: 0.8387 - val_loss: 0.6509\nEpoch 497/550\n18/18 - 0s - 5ms/step - accuracy: 0.9366 - loss: 0.1998 - val_accuracy: 0.8387 - val_loss: 0.5823\nEpoch 498/550\n18/18 - 0s - 8ms/step - accuracy: 0.9475 - loss: 0.1954 - val_accuracy: 0.8387 - val_loss: 0.6023\nEpoch 499/550\n18/18 - 0s - 4ms/step - accuracy: 0.9438 - loss: 0.1928 - val_accuracy: 0.8387 - val_loss: 0.6288\nEpoch 500/550\n18/18 - 0s - 4ms/step - accuracy: 0.9438 - loss: 0.1926 - val_accuracy: 0.8387 - val_loss: 0.6529\nEpoch 501/550\n18/18 - 0s - 9ms/step - accuracy: 0.9457 - loss: 0.1920 - val_accuracy: 0.8387 - val_loss: 0.6440\nEpoch 502/550\n18/18 - 0s - 6ms/step - accuracy: 0.9420 - loss: 0.1924 - val_accuracy: 0.8387 - val_loss: 0.6290\nEpoch 503/550\n18/18 - 0s - 5ms/step - accuracy: 0.9420 - loss: 0.1932 - val_accuracy: 0.8387 - val_loss: 0.6492\nEpoch 504/550\n18/18 - 0s - 6ms/step - accuracy: 0.9438 - loss: 0.1943 - val_accuracy: 0.8387 - val_loss: 0.7120\nEpoch 505/550\n18/18 - 0s - 5ms/step - accuracy: 0.9420 - loss: 0.1924 - val_accuracy: 0.8548 - val_loss: 0.5275\nEpoch 506/550\n18/18 - 0s - 5ms/step - accuracy: 0.9420 - loss: 0.2023 - val_accuracy: 0.8387 - val_loss: 0.7961\nEpoch 507/550\n18/18 - 0s - 5ms/step - accuracy: 0.9438 - loss: 0.2056 - val_accuracy: 0.8226 - val_loss: 0.6107\nEpoch 508/550\n18/18 - 0s - 8ms/step - accuracy: 0.9420 - loss: 0.2008 - val_accuracy: 0.8387 - val_loss: 0.7111\nEpoch 509/550\n18/18 - 0s - 8ms/step - accuracy: 0.9438 - loss: 0.1930 - val_accuracy: 0.8387 - val_loss: 0.6704\nEpoch 510/550\n18/18 - 0s - 5ms/step - accuracy: 0.9402 - loss: 0.1992 - val_accuracy: 0.8387 - val_loss: 0.6739\nEpoch 511/550\n18/18 - 0s - 8ms/step - accuracy: 0.9348 - loss: 0.2060 - val_accuracy: 0.8387 - val_loss: 0.6905\nEpoch 512/550\n18/18 - 0s - 8ms/step - accuracy: 0.9438 - loss: 0.2009 - val_accuracy: 0.8387 - val_loss: 0.6067\nEpoch 513/550\n18/18 - 0s - 5ms/step - accuracy: 0.9330 - loss: 0.2215 - val_accuracy: 0.8548 - val_loss: 0.5705\nEpoch 514/550\n18/18 - 0s - 5ms/step - accuracy: 0.9402 - loss: 0.2120 - val_accuracy: 0.8387 - val_loss: 0.6281\nEpoch 515/550\n18/18 - 0s - 8ms/step - accuracy: 0.9420 - loss: 0.1981 - val_accuracy: 0.8387 - val_loss: 0.7015\nEpoch 516/550\n18/18 - 0s - 5ms/step - accuracy: 0.9438 - loss: 0.1936 - val_accuracy: 0.8387 - val_loss: 0.6740\nEpoch 517/550\n18/18 - 0s - 5ms/step - accuracy: 0.9457 - loss: 0.1936 - val_accuracy: 0.8387 - val_loss: 0.7194\nEpoch 518/550\n18/18 - 0s - 8ms/step - accuracy: 0.9438 - loss: 0.1952 - val_accuracy: 0.8387 - val_loss: 0.7535\nEpoch 519/550\n18/18 - 0s - 4ms/step - accuracy: 0.9239 - loss: 0.2450 - val_accuracy: 0.8226 - val_loss: 0.6910\nEpoch 520/550\n18/18 - 0s - 4ms/step - accuracy: 0.9293 - loss: 0.2194 - val_accuracy: 0.8226 - val_loss: 0.6615\nEpoch 521/550\n18/18 - 0s - 5ms/step - accuracy: 0.9257 - loss: 0.2292 - val_accuracy: 0.7903 - val_loss: 0.8172\nEpoch 522/550\n18/18 - 0s - 5ms/step - accuracy: 0.9275 - loss: 0.2368 - val_accuracy: 0.8226 - val_loss: 0.4826\nEpoch 523/550\n18/18 - 0s - 8ms/step - accuracy: 0.9348 - loss: 0.2169 - val_accuracy: 0.8387 - val_loss: 0.5188\nEpoch 524/550\n18/18 - 0s - 7ms/step - accuracy: 0.9402 - loss: 0.2152 - val_accuracy: 0.8387 - val_loss: 0.5027\nEpoch 525/550\n18/18 - 0s - 8ms/step - accuracy: 0.9366 - loss: 0.2219 - val_accuracy: 0.8710 - val_loss: 0.4372\nEpoch 526/550\n18/18 - 0s - 8ms/step - accuracy: 0.9402 - loss: 0.2075 - val_accuracy: 0.8387 - val_loss: 0.7222\nEpoch 527/550\n18/18 - 0s - 8ms/step - accuracy: 0.9348 - loss: 0.2195 - val_accuracy: 0.8387 - val_loss: 0.8986\nEpoch 528/550\n18/18 - 0s - 6ms/step - accuracy: 0.9076 - loss: 0.2797 - val_accuracy: 0.8226 - val_loss: 0.5745\nEpoch 529/550\n18/18 - 0s - 8ms/step - accuracy: 0.9130 - loss: 0.2672 - val_accuracy: 0.8226 - val_loss: 0.6100\nEpoch 530/550\n18/18 - 0s - 7ms/step - accuracy: 0.9312 - loss: 0.2173 - val_accuracy: 0.8548 - val_loss: 0.7162\nEpoch 531/550\n18/18 - 0s - 8ms/step - accuracy: 0.9312 - loss: 0.2279 - val_accuracy: 0.8548 - val_loss: 0.5408\nEpoch 532/550\n18/18 - 0s - 8ms/step - accuracy: 0.9330 - loss: 0.2165 - val_accuracy: 0.8871 - val_loss: 0.5002\nEpoch 533/550\n18/18 - 0s - 7ms/step - accuracy: 0.9402 - loss: 0.2003 - val_accuracy: 0.8548 - val_loss: 0.7769\nEpoch 534/550\n18/18 - 0s - 5ms/step - accuracy: 0.9475 - loss: 0.1905 - val_accuracy: 0.8548 - val_loss: 0.7274\nEpoch 535/550\n18/18 - 0s - 8ms/step - accuracy: 0.9457 - loss: 0.1925 - val_accuracy: 0.8548 - val_loss: 0.6553\nEpoch 536/550\n18/18 - 0s - 5ms/step - accuracy: 0.9420 - loss: 0.1931 - val_accuracy: 0.8548 - val_loss: 0.6054\nEpoch 537/550\n18/18 - 0s - 8ms/step - accuracy: 0.9457 - loss: 0.1886 - val_accuracy: 0.8387 - val_loss: 0.6153\nEpoch 538/550\n18/18 - 0s - 5ms/step - accuracy: 0.9457 - loss: 0.1869 - val_accuracy: 0.8548 - val_loss: 0.9091\nEpoch 539/550\n18/18 - 0s - 5ms/step - accuracy: 0.9420 - loss: 0.2107 - val_accuracy: 0.8226 - val_loss: 0.5928\nEpoch 540/550\n18/18 - 0s - 8ms/step - accuracy: 0.9438 - loss: 0.1885 - val_accuracy: 0.8548 - val_loss: 0.6156\nEpoch 541/550\n18/18 - 0s - 5ms/step - accuracy: 0.9475 - loss: 0.1871 - val_accuracy: 0.8387 - val_loss: 0.5969\nEpoch 542/550\n18/18 - 0s - 8ms/step - accuracy: 0.9457 - loss: 0.1948 - val_accuracy: 0.8387 - val_loss: 0.5887\nEpoch 543/550\n18/18 - 0s - 8ms/step - accuracy: 0.9493 - loss: 0.1843 - val_accuracy: 0.8387 - val_loss: 0.6691\nEpoch 544/550\n18/18 - 0s - 8ms/step - accuracy: 0.9493 - loss: 0.1826 - val_accuracy: 0.8387 - val_loss: 0.6580\nEpoch 545/550\n18/18 - 0s - 8ms/step - accuracy: 0.9402 - loss: 0.2017 - val_accuracy: 0.8387 - val_loss: 0.6719\nEpoch 546/550\n18/18 - 0s - 5ms/step - accuracy: 0.9457 - loss: 0.1941 - val_accuracy: 0.8387 - val_loss: 0.7456\nEpoch 547/550\n18/18 - 0s - 7ms/step - accuracy: 0.9493 - loss: 0.1836 - val_accuracy: 0.8387 - val_loss: 0.7588\nEpoch 548/550\n18/18 - 0s - 8ms/step - accuracy: 0.9493 - loss: 0.1843 - val_accuracy: 0.8387 - val_loss: 0.7132\nEpoch 549/550\n18/18 - 0s - 9ms/step - accuracy: 0.9438 - loss: 0.1829 - val_accuracy: 0.8387 - val_loss: 0.6858\nEpoch 550/550\n18/18 - 0s - 7ms/step - accuracy: 0.9493 - loss: 0.1797 - val_accuracy: 0.8387 - val_loss: 0.7370\n","output_type":"stream"}]},{"cell_type":"code","source":"# Lets measure final performance\nhist = pd.DataFrame(neural_pred.history)\nhist['epoch'] = neural_pred.epoch\nhist.tail()","metadata":{"id":"5xa0NIi-ILEl","outputId":"2445e750-eab7-4c9e-cc03-731809d2b3ba","papermill":{"duration":0.227356,"end_time":"2024-05-15T03:42:17.500585","exception":false,"start_time":"2024-05-15T03:42:17.273229","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-28T20:33:26.654651Z","iopub.execute_input":"2024-05-28T20:33:26.655189Z","iopub.status.idle":"2024-05-28T20:33:26.674486Z","shell.execute_reply.started":"2024-05-28T20:33:26.655130Z","shell.execute_reply":"2024-05-28T20:33:26.673219Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"     accuracy      loss  val_accuracy  val_loss  epoch\n545  0.945652  0.194108       0.83871  0.745599    545\n546  0.949275  0.183601       0.83871  0.758848    546\n547  0.949275  0.184281       0.83871  0.713184    547\n548  0.943841  0.182873       0.83871  0.685806    548\n549  0.949275  0.179686       0.83871  0.736959    549","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>accuracy</th>\n      <th>loss</th>\n      <th>val_accuracy</th>\n      <th>val_loss</th>\n      <th>epoch</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>545</th>\n      <td>0.945652</td>\n      <td>0.194108</td>\n      <td>0.83871</td>\n      <td>0.745599</td>\n      <td>545</td>\n    </tr>\n    <tr>\n      <th>546</th>\n      <td>0.949275</td>\n      <td>0.183601</td>\n      <td>0.83871</td>\n      <td>0.758848</td>\n      <td>546</td>\n    </tr>\n    <tr>\n      <th>547</th>\n      <td>0.949275</td>\n      <td>0.184281</td>\n      <td>0.83871</td>\n      <td>0.713184</td>\n      <td>547</td>\n    </tr>\n    <tr>\n      <th>548</th>\n      <td>0.943841</td>\n      <td>0.182873</td>\n      <td>0.83871</td>\n      <td>0.685806</td>\n      <td>548</td>\n    </tr>\n    <tr>\n      <th>549</th>\n      <td>0.949275</td>\n      <td>0.179686</td>\n      <td>0.83871</td>\n      <td>0.736959</td>\n      <td>549</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"neural_test = neural_model.predict(X_test)","metadata":{"id":"0EPgaU-3GLIf","outputId":"53a552f8-63ad-4de2-a64f-0e51a01ccd00","papermill":{"duration":0.404715,"end_time":"2024-05-15T03:42:18.109020","exception":false,"start_time":"2024-05-15T03:42:17.704305","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-28T20:33:26.681355Z","iopub.execute_input":"2024-05-28T20:33:26.681932Z","iopub.status.idle":"2024-05-28T20:33:26.906342Z","shell.execute_reply.started":"2024-05-28T20:33:26.681877Z","shell.execute_reply":"2024-05-28T20:33:26.904953Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"neural_test_converted=[]\nfor i in neural_test:\n    if i>0.5:\n        neural_test_converted.append(1)\n    else:\n        neural_test_converted.append(0)","metadata":{"id":"i2dYRKOnH8lO","papermill":{"duration":0.218445,"end_time":"2024-05-15T03:42:18.531047","exception":false,"start_time":"2024-05-15T03:42:18.312602","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-28T20:33:26.908526Z","iopub.execute_input":"2024-05-28T20:33:26.908944Z","iopub.status.idle":"2024-05-28T20:33:26.915881Z","shell.execute_reply.started":"2024-05-28T20:33:26.908911Z","shell.execute_reply":"2024-05-28T20:33:26.914873Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"cmp = model_pref(neural_test_converted, y_test)","metadata":{"id":"dp3rDiWtITG4","papermill":{"duration":0.21911,"end_time":"2024-05-15T03:42:18.961491","exception":false,"start_time":"2024-05-15T03:42:18.742381","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-28T20:33:26.917718Z","iopub.execute_input":"2024-05-28T20:33:26.918466Z","iopub.status.idle":"2024-05-28T20:33:26.933548Z","shell.execute_reply.started":"2024-05-28T20:33:26.918422Z","shell.execute_reply":"2024-05-28T20:33:26.931776Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"print(\"Test Accuracy: \",str(round(cmp.count(1)/ len(y_test)*100,2))+\"%\")","metadata":{"id":"c2_dVl3EIvmd","outputId":"3304617c-4940-4d94-a0a9-3d1219728258","papermill":{"duration":0.215497,"end_time":"2024-05-15T03:42:19.382725","exception":false,"start_time":"2024-05-15T03:42:19.167228","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-28T20:33:26.935534Z","iopub.execute_input":"2024-05-28T20:33:26.936541Z","iopub.status.idle":"2024-05-28T20:33:26.945413Z","shell.execute_reply.started":"2024-05-28T20:33:26.936488Z","shell.execute_reply":"2024-05-28T20:33:26.943840Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Test Accuracy:  84.42%\n","output_type":"stream"}]},{"cell_type":"markdown","source":"SVM is Good to go","metadata":{"id":"WgIO_diZKYS-","papermill":{"duration":0.207626,"end_time":"2024-05-15T03:42:19.799865","exception":false,"start_time":"2024-05-15T03:42:19.592239","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"Save the model","metadata":{"id":"tSzrNDqpKw_m","papermill":{"duration":0.203207,"end_time":"2024-05-15T03:42:20.209595","exception":false,"start_time":"2024-05-15T03:42:20.006388","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import pickle\npickle.dump(svm_model, open(\"svm_model.pkl\", 'wb') )","metadata":{"id":"TfLPX_ZXKiTb","papermill":{"duration":0.21622,"end_time":"2024-05-15T03:42:20.629219","exception":false,"start_time":"2024-05-15T03:42:20.412999","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-28T20:33:26.947455Z","iopub.execute_input":"2024-05-28T20:33:26.948197Z","iopub.status.idle":"2024-05-28T20:33:26.963420Z","shell.execute_reply.started":"2024-05-28T20:33:26.948137Z","shell.execute_reply":"2024-05-28T20:33:26.961817Z"},"trusted":true},"execution_count":32,"outputs":[]}]}